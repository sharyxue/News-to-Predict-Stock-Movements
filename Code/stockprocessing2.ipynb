{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "i_WRd4bhtuVh",
    "outputId": "6d0a37da-0cd9-4d94-de2b-308a143c9e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tushare\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/33/787d66827e97ba54bcfde43c95f573c45a61456b61a7f1e72f24d908d8b4/tushare-1.2.36.tar.gz (168kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 4.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (0.24.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (2.21.0)\n",
      "Requirement already satisfied: lxml>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (4.2.6)\n",
      "Collecting simplejson>=3.16.0 (from tushare)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/24/c35fb1c1c315fc0fffe61ea00d3f88e85469004713dab488dee4f35b0aff/simplejson-3.16.0.tar.gz (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 26.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: bs4>=0.0.1 in /usr/local/lib/python3.6/dist-packages (from tushare) (0.0.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->tushare) (1.16.4)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->tushare) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->tushare) (2.5.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (1.24.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4>=0.0.1->tushare) (4.6.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.18.0->tushare) (1.12.0)\n",
      "Building wheels for collected packages: tushare, simplejson\n",
      "  Building wheel for tushare (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/1a/9e/9d75d1da33706bb22e812e81b58716b49ea731f43dfa73f5c2\n",
      "  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/5d/1a/1e/0350bb3df3e74215cd91325344cc86c2c691f5306eb4d22c77\n",
      "Successfully built tushare simplejson\n",
      "Installing collected packages: simplejson, tushare\n",
      "Successfully installed simplejson-3.16.0 tushare-1.2.36\n"
     ]
    }
   ],
   "source": [
    "# !pip install tushare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "U9LoaRqitvvU",
    "outputId": "1feb9eca-4321-4c90-b02c-aea966d6f0f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.1.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "80GjRvkWt-rw",
    "outputId": "b7ee66fd-fdbb-4c70-effb-3f4d3b185003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tushare in /usr/local/lib/python3.6/dist-packages (1.2.36)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: bs4>=0.0.1 in /usr/local/lib/python3.6/dist-packages (from tushare) (0.0.1)\n",
      "Requirement already satisfied, skipping upgrade: simplejson>=3.16.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (3.16.0)\n",
      "Requirement already satisfied, skipping upgrade: lxml>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (4.2.6)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4>=0.0.1->tushare) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->tushare) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->tushare) (2.5.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->tushare) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.18.0->tushare) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tushare --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T04:11:59.115909Z",
     "start_time": "2019-05-25T04:11:59.020966Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "LFLc-ooh5wTh",
    "outputId": "952b3120-e168-4941-fb98-a3322c6bab8a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.externals import joblib\n",
    "import warnings\n",
    "import tushare as ts\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wPYNlDDuIBs"
   },
   "outputs": [],
   "source": [
    "pro = ts.pro_api('52119551ebc32c734a42fd61ccf33344fde3c6195b0aacec58d15140')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcFYK1bSUXvz"
   },
   "source": [
    "# 特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T04:24:07.795105Z",
     "start_time": "2019-05-25T04:24:07.765127Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Vzdq3q8DUXv1"
   },
   "outputs": [],
   "source": [
    "colums=['801010.SI', '801020.SI', '801030.SI','801040.SI', '801050.SI', '801080.SI', '801110.SI', '801120.SI',\n",
    "        '801130.SI', '801140.SI', '801150.SI', '801160.SI', '801170.SI', '801180.SI', '801200.SI', '801210.SI',\n",
    "        '801230.SI', '801250.SI', '801260.SI', '801270.SI', '801280.SI', '801300.SI', '801710.SI', '801720.SI',\n",
    "        '801730.SI', '801740.SI', '801750.SI', '801760.SI', '801770.SI', '801780.SI', '801790.SI', '801880.SI',\n",
    "        '801890.SI', '802600.SI']\n",
    "df_pr = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "for arr in colums:\n",
    "    df2=pro.sw_daily(ts_code=arr, start_date='20130101', end_date='20190626')\n",
    "    df2=df2.sort_values(by=\"trade_date\",ascending= True)\n",
    "    df = pd.concat([df, df2])\n",
    "df.loc[df['pct_change']>0,'y']=1\n",
    "df.loc[df['pct_change']<0,'y']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "C__h_mVIxjKF",
    "outputId": "92baa116-6586-440c-ca74-8ec88cef46fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>name</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>pe</th>\n",
       "      <th>pb</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>801010.SI</td>\n",
       "      <td>20150204</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>2405.68</td>\n",
       "      <td>2383.01</td>\n",
       "      <td>2406.61</td>\n",
       "      <td>2384.64</td>\n",
       "      <td>-20.68</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>65282.0</td>\n",
       "      <td>733331.0</td>\n",
       "      <td>57.79</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>801010.SI</td>\n",
       "      <td>20150205</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>2408.53</td>\n",
       "      <td>2369.49</td>\n",
       "      <td>2415.44</td>\n",
       "      <td>2370.47</td>\n",
       "      <td>-14.16</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>75076.0</td>\n",
       "      <td>846512.0</td>\n",
       "      <td>57.45</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>801010.SI</td>\n",
       "      <td>20150206</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>2366.41</td>\n",
       "      <td>2320.88</td>\n",
       "      <td>2367.78</td>\n",
       "      <td>2330.24</td>\n",
       "      <td>-40.23</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>76395.0</td>\n",
       "      <td>796091.0</td>\n",
       "      <td>56.48</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>801010.SI</td>\n",
       "      <td>20150209</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>2328.82</td>\n",
       "      <td>2316.95</td>\n",
       "      <td>2335.93</td>\n",
       "      <td>2321.64</td>\n",
       "      <td>-8.60</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>47210.0</td>\n",
       "      <td>525855.0</td>\n",
       "      <td>56.27</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>801010.SI</td>\n",
       "      <td>20150210</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>2320.43</td>\n",
       "      <td>2317.66</td>\n",
       "      <td>2332.02</td>\n",
       "      <td>2332.02</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>38513.0</td>\n",
       "      <td>419652.0</td>\n",
       "      <td>56.52</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ts_code trade_date  name     open      low     high    close  change  \\\n",
       "999  801010.SI   20150204  农林牧渔  2405.68  2383.01  2406.61  2384.64  -20.68   \n",
       "998  801010.SI   20150205  农林牧渔  2408.53  2369.49  2415.44  2370.47  -14.16   \n",
       "997  801010.SI   20150206  农林牧渔  2366.41  2320.88  2367.78  2330.24  -40.23   \n",
       "996  801010.SI   20150209  农林牧渔  2328.82  2316.95  2335.93  2321.64   -8.60   \n",
       "995  801010.SI   20150210  农林牧渔  2320.43  2317.66  2332.02  2332.02   10.38   \n",
       "\n",
       "     pct_change      vol    amount     pe    pb    y  \n",
       "999       -0.86  65282.0  733331.0  57.79  3.63  0.0  \n",
       "998       -0.59  75076.0  846512.0  57.45  3.61  0.0  \n",
       "997       -1.70  76395.0  796091.0  56.48  3.55  0.0  \n",
       "996       -0.37  47210.0  525855.0  56.27  3.54  0.0  \n",
       "995        0.45  38513.0  419652.0  56.52  3.55  1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T04:25:54.546256Z",
     "start_time": "2019-05-25T04:25:54.483295Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "VjqF0fnlTUuc"
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for arr in colums:\n",
    "    df1=df.loc[df['ts_code']==arr]\n",
    "    df1=df1[['ts_code','trade_date','name','low','high','close','pct_change','vol','y']]\n",
    "    df1['vol_change'] = df1['vol'].pct_change()\n",
    "    df1['low_change'] = df1['low'].pct_change()\n",
    "    df1['high_change'] = df1['high'].pct_change()\n",
    "    df1['gaodi']=(df1['high']-df1['low'])/df1['low']\n",
    "    df1['gaoclo']=(df1['high']-df1['close'])/(df1['high']-df1['low'])\n",
    "    df1['diclo']=(df1['close']-df1['low'])/(df1['high']-df1['low'])\n",
    "    df1['pct_change']=df1['pct_change']/10\n",
    "    df1=df1[['pct_change','vol_change','high_change','low_change','gaodi','gaoclo','diclo','y']]\n",
    "    df1= df1.dropna()\n",
    "    dataset=df1.values\n",
    "    for i in range(len(dataset)-17):\n",
    "        x.append(dataset[i:(i+15),:8].tolist())\n",
    "        y.append(dataset[(i+15):(i+16),7,np.newaxis].tolist())\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.1, random_state=30)\n",
    "xtrain, xtest, ytrain, ytest = np.array(xtrain),np.array(xtest),np.array(ytrain),np.array(ytest)\n",
    "# xtrain = np.reshape(xtrain, (xtrain.shape[0], xtrain.shape[2]))\n",
    "# xtest = np.reshape(xtest, (xtest.shape[0], xtest.shape[2]))\n",
    "ytrain = np.reshape(ytrain, (ytrain.shape[0], ytrain.shape[1]))\n",
    "ytest= np.reshape(ytest, (ytest.shape[0], ytest.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VIIQvEzxfYLq",
    "outputId": "16c4360e-831c-4ca5-d730-108c11acdf47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29935, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5w1qmY05wTt"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T04:26:49.270427Z",
     "start_time": "2019-05-25T04:25:58.920725Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wYtriXrZ5wTu"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout,Activation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from keras import layers\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "busktUTg6mGu",
    "outputId": "39f729c8-788b-48f6-b189-f041d0226a2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['农林牧渔', '采掘', '化工', '钢铁', '有色金属', '电子', '家用电器', '食品饮料', '纺织服装',\n",
       "        '轻工制造', '医药生物', '公用事业', '交通运输', '房地产', '商业贸易', '休闲服务', '综合',\n",
       "        '申万制造', '申万消费', '申万投资', '申万服务', '申万300指数', '建筑材料', '建筑装饰',\n",
       "        '电气设备', '国防军工', '计算机', '传媒', '通信', '银行', '非银金融', '汽车', '机械设备',\n",
       "        '交银装备']], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 行业名字和行业代码的对应\n",
    "# df_test4=\n",
    "# df_me=pd.DataFrame(df_test4[['ts_code','name']])\n",
    "# df_me=df_me.drop_duplicates()\n",
    "# df_me\n",
    "# df8=df_me[['name']]\n",
    "# df8=df8.T\n",
    "# df8.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvmtHpHZUXyk"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=520)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zAZXsJgo5wT9",
    "outputId": "39598f7e-2e5f-48a8-ed56-7bcf39de309e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold\n",
      "Epoch 1/100\n",
      "23948/23948 [==============================] - 42s 2ms/step - loss: 0.6917 - acc: 0.5220\n",
      "Epoch 2/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6907 - acc: 0.5267\n",
      "Epoch 3/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6891 - acc: 0.5367\n",
      "Epoch 4/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6882 - acc: 0.5342\n",
      "Epoch 5/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6863 - acc: 0.5405\n",
      "Epoch 6/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6840 - acc: 0.5464\n",
      "Epoch 7/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6830 - acc: 0.5497\n",
      "Epoch 8/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6808 - acc: 0.5489\n",
      "Epoch 9/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6763 - acc: 0.5579\n",
      "Epoch 10/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6737 - acc: 0.5639\n",
      "Epoch 11/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6697 - acc: 0.5681\n",
      "Epoch 12/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6676 - acc: 0.5722\n",
      "Epoch 13/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6631 - acc: 0.5775\n",
      "Epoch 14/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6578 - acc: 0.5826\n",
      "Epoch 15/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6524 - acc: 0.5919\n",
      "Epoch 16/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6462 - acc: 0.6002\n",
      "Epoch 17/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6422 - acc: 0.6033\n",
      "Epoch 18/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6371 - acc: 0.6094\n",
      "Epoch 19/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6279 - acc: 0.6212\n",
      "Epoch 20/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6215 - acc: 0.6302\n",
      "Epoch 21/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.6126 - acc: 0.6386\n",
      "Epoch 22/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6008 - acc: 0.6477\n",
      "Epoch 23/100\n",
      "23948/23948 [==============================] - 23s 970us/step - loss: 0.5938 - acc: 0.6542\n",
      "Epoch 24/100\n",
      "23948/23948 [==============================] - 23s 970us/step - loss: 0.5845 - acc: 0.6659\n",
      "Epoch 25/100\n",
      "23948/23948 [==============================] - 23s 971us/step - loss: 0.5777 - acc: 0.6716\n",
      "Epoch 26/100\n",
      "23948/23948 [==============================] - 23s 971us/step - loss: 0.5682 - acc: 0.6805\n",
      "Epoch 27/100\n",
      "23948/23948 [==============================] - 23s 968us/step - loss: 0.5563 - acc: 0.6911\n",
      "Epoch 28/100\n",
      "23948/23948 [==============================] - 23s 973us/step - loss: 0.5497 - acc: 0.6957\n",
      "Epoch 29/100\n",
      "23948/23948 [==============================] - 23s 972us/step - loss: 0.5464 - acc: 0.6971\n",
      "Epoch 30/100\n",
      "23948/23948 [==============================] - 23s 971us/step - loss: 0.5320 - acc: 0.7116\n",
      "Epoch 31/100\n",
      "23948/23948 [==============================] - 23s 971us/step - loss: 0.5219 - acc: 0.7186\n",
      "Epoch 32/100\n",
      "23948/23948 [==============================] - 23s 976us/step - loss: 0.5178 - acc: 0.7191\n",
      "Epoch 33/100\n",
      "23948/23948 [==============================] - 23s 969us/step - loss: 0.5053 - acc: 0.7274\n",
      "Epoch 34/100\n",
      "23948/23948 [==============================] - 23s 972us/step - loss: 0.4987 - acc: 0.7349\n",
      "Epoch 35/100\n",
      "23948/23948 [==============================] - 23s 969us/step - loss: 0.4934 - acc: 0.7399\n",
      "Epoch 36/100\n",
      "23948/23948 [==============================] - 23s 962us/step - loss: 0.4854 - acc: 0.7495\n",
      "Epoch 37/100\n",
      "23948/23948 [==============================] - 23s 969us/step - loss: 0.4745 - acc: 0.7537\n",
      "Epoch 38/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.4662 - acc: 0.7562\n",
      "Epoch 39/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.4590 - acc: 0.7644\n",
      "Epoch 40/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.4529 - acc: 0.7711\n",
      "Epoch 41/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.4490 - acc: 0.7730\n",
      "Epoch 42/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.4380 - acc: 0.7811\n",
      "Epoch 43/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.4321 - acc: 0.7848\n",
      "Epoch 44/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.4257 - acc: 0.7916\n",
      "Epoch 45/100\n",
      "23948/23948 [==============================] - 24s 996us/step - loss: 0.4168 - acc: 0.7918\n",
      "Epoch 46/100\n",
      "23948/23948 [==============================] - 23s 942us/step - loss: 0.4079 - acc: 0.8014\n",
      "Epoch 47/100\n",
      "23948/23948 [==============================] - 23s 977us/step - loss: 0.4034 - acc: 0.8011\n",
      "Epoch 48/100\n",
      "23948/23948 [==============================] - 24s 986us/step - loss: 0.3955 - acc: 0.8061\n",
      "Epoch 49/100\n",
      "23948/23948 [==============================] - 24s 990us/step - loss: 0.3853 - acc: 0.8131\n",
      "Epoch 50/100\n",
      "23948/23948 [==============================] - 24s 984us/step - loss: 0.3830 - acc: 0.8145\n",
      "Epoch 51/100\n",
      "23948/23948 [==============================] - 24s 988us/step - loss: 0.3773 - acc: 0.8178\n",
      "Epoch 52/100\n",
      "23948/23948 [==============================] - 24s 982us/step - loss: 0.3663 - acc: 0.8218\n",
      "Epoch 53/100\n",
      "23948/23948 [==============================] - 24s 983us/step - loss: 0.3658 - acc: 0.8239\n",
      "Epoch 54/100\n",
      "23948/23948 [==============================] - 24s 984us/step - loss: 0.3572 - acc: 0.8300\n",
      "Epoch 55/100\n",
      "23948/23948 [==============================] - 24s 985us/step - loss: 0.3529 - acc: 0.8307\n",
      "Epoch 56/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.3477 - acc: 0.8388\n",
      "Epoch 57/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.3382 - acc: 0.8416\n",
      "Epoch 58/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3344 - acc: 0.8442\n",
      "Epoch 59/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3294 - acc: 0.8478\n",
      "Epoch 60/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3239 - acc: 0.8518\n",
      "Epoch 61/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.3162 - acc: 0.8540\n",
      "Epoch 62/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.3146 - acc: 0.8551\n",
      "Epoch 63/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3057 - acc: 0.8603\n",
      "Epoch 64/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3039 - acc: 0.8615\n",
      "Epoch 65/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2948 - acc: 0.8663\n",
      "Epoch 66/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2917 - acc: 0.8677\n",
      "Epoch 67/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2827 - acc: 0.8752\n",
      "Epoch 68/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2806 - acc: 0.8758\n",
      "Epoch 69/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2797 - acc: 0.8741\n",
      "Epoch 70/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2743 - acc: 0.8774\n",
      "Epoch 71/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2681 - acc: 0.8830\n",
      "Epoch 72/100\n",
      "23948/23948 [==============================] - 23s 981us/step - loss: 0.2629 - acc: 0.8821\n",
      "Epoch 73/100\n",
      "23948/23948 [==============================] - 23s 980us/step - loss: 0.2589 - acc: 0.8863\n",
      "Epoch 74/100\n",
      "23948/23948 [==============================] - 23s 979us/step - loss: 0.2566 - acc: 0.8863\n",
      "Epoch 75/100\n",
      "23948/23948 [==============================] - 24s 983us/step - loss: 0.2561 - acc: 0.8888\n",
      "Epoch 76/100\n",
      "23948/23948 [==============================] - 23s 981us/step - loss: 0.2401 - acc: 0.8954\n",
      "Epoch 77/100\n",
      "23948/23948 [==============================] - 23s 980us/step - loss: 0.2419 - acc: 0.8944\n",
      "Epoch 78/100\n",
      "23948/23948 [==============================] - 24s 982us/step - loss: 0.2389 - acc: 0.8977\n",
      "Epoch 79/100\n",
      "23948/23948 [==============================] - 24s 982us/step - loss: 0.2383 - acc: 0.8970\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23948/23948 [==============================] - 23s 973us/step - loss: 0.2325 - acc: 0.8990\n",
      "Epoch 81/100\n",
      "23948/23948 [==============================] - 23s 971us/step - loss: 0.2293 - acc: 0.8995\n",
      "Epoch 82/100\n",
      "23948/23948 [==============================] - 23s 975us/step - loss: 0.2260 - acc: 0.9027\n",
      "Epoch 83/100\n",
      "23948/23948 [==============================] - 23s 976us/step - loss: 0.2250 - acc: 0.9046\n",
      "Epoch 84/100\n",
      "23948/23948 [==============================] - 24s 988us/step - loss: 0.2159 - acc: 0.9073\n",
      "Epoch 85/100\n",
      "23948/23948 [==============================] - 23s 980us/step - loss: 0.2214 - acc: 0.9038\n",
      "Epoch 86/100\n",
      "23948/23948 [==============================] - 23s 974us/step - loss: 0.2096 - acc: 0.9111\n",
      "Epoch 87/100\n",
      "23948/23948 [==============================] - 23s 975us/step - loss: 0.2084 - acc: 0.9124\n",
      "Epoch 88/100\n",
      "23948/23948 [==============================] - 23s 976us/step - loss: 0.2108 - acc: 0.9110\n",
      "Epoch 89/100\n",
      "23948/23948 [==============================] - 23s 976us/step - loss: 0.2055 - acc: 0.9147\n",
      "Epoch 90/100\n",
      "23948/23948 [==============================] - 24s 993us/step - loss: 0.1959 - acc: 0.9168\n",
      "Epoch 91/100\n",
      "23948/23948 [==============================] - 23s 980us/step - loss: 0.2015 - acc: 0.9160\n",
      "Epoch 92/100\n",
      "23948/23948 [==============================] - 23s 981us/step - loss: 0.1920 - acc: 0.9197\n",
      "Epoch 93/100\n",
      "23948/23948 [==============================] - 24s 990us/step - loss: 0.1931 - acc: 0.9190\n",
      "Epoch 94/100\n",
      "23948/23948 [==============================] - 23s 975us/step - loss: 0.1913 - acc: 0.9187\n",
      "Epoch 95/100\n",
      "23948/23948 [==============================] - 24s 981us/step - loss: 0.1857 - acc: 0.9239\n",
      "Epoch 96/100\n",
      "23948/23948 [==============================] - 23s 970us/step - loss: 0.1817 - acc: 0.9242\n",
      "Epoch 97/100\n",
      "23948/23948 [==============================] - 23s 974us/step - loss: 0.1813 - acc: 0.9243\n",
      "Epoch 98/100\n",
      "23948/23948 [==============================] - 23s 968us/step - loss: 0.1758 - acc: 0.9272\n",
      "Epoch 99/100\n",
      "23948/23948 [==============================] - 23s 968us/step - loss: 0.1765 - acc: 0.9261\n",
      "Epoch 100/100\n",
      "23948/23948 [==============================] - 23s 972us/step - loss: 0.1754 - acc: 0.9283\n",
      "0.8169808362700997\n",
      "0.8157828126929252\n",
      "1 fold\n",
      "Epoch 1/100\n",
      "23948/23948 [==============================] - 37s 2ms/step - loss: 0.6922 - acc: 0.5194\n",
      "Epoch 2/100\n",
      "23948/23948 [==============================] - 23s 958us/step - loss: 0.6910 - acc: 0.5258\n",
      "Epoch 3/100\n",
      "23948/23948 [==============================] - 23s 964us/step - loss: 0.6891 - acc: 0.5333\n",
      "Epoch 4/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6871 - acc: 0.5360\n",
      "Epoch 5/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6860 - acc: 0.5380\n",
      "Epoch 6/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6848 - acc: 0.5414\n",
      "Epoch 7/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6842 - acc: 0.5454\n",
      "Epoch 8/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6831 - acc: 0.5471\n",
      "Epoch 9/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6815 - acc: 0.5526\n",
      "Epoch 10/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6782 - acc: 0.5570\n",
      "Epoch 11/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6741 - acc: 0.5668\n",
      "Epoch 12/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6687 - acc: 0.5761\n",
      "Epoch 13/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6604 - acc: 0.5884\n",
      "Epoch 14/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6493 - acc: 0.5978\n",
      "Epoch 15/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6384 - acc: 0.6099\n",
      "Epoch 16/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6261 - acc: 0.6249\n",
      "Epoch 17/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6132 - acc: 0.6398\n",
      "Epoch 18/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6004 - acc: 0.6509\n",
      "Epoch 19/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5894 - acc: 0.6599\n",
      "Epoch 20/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5752 - acc: 0.6724\n",
      "Epoch 21/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5627 - acc: 0.6830\n",
      "Epoch 22/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5528 - acc: 0.6907\n",
      "Epoch 23/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5426 - acc: 0.7045\n",
      "Epoch 24/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5314 - acc: 0.7132\n",
      "Epoch 25/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5213 - acc: 0.7207\n",
      "Epoch 26/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5131 - acc: 0.7249\n",
      "Epoch 27/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5002 - acc: 0.7368\n",
      "Epoch 28/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.4921 - acc: 0.7412\n",
      "Epoch 29/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4842 - acc: 0.7452\n",
      "Epoch 30/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4728 - acc: 0.7562\n",
      "Epoch 31/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4639 - acc: 0.7623\n",
      "Epoch 32/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4598 - acc: 0.7657\n",
      "Epoch 33/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4497 - acc: 0.7713\n",
      "Epoch 34/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.4372 - acc: 0.7784\n",
      "Epoch 35/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.4303 - acc: 0.7833\n",
      "Epoch 36/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4234 - acc: 0.7882\n",
      "Epoch 37/100\n",
      "23948/23948 [==============================] - 23s 973us/step - loss: 0.4143 - acc: 0.7962\n",
      "Epoch 38/100\n",
      "23948/23948 [==============================] - 23s 957us/step - loss: 0.4093 - acc: 0.7986\n",
      "Epoch 39/100\n",
      "23948/23948 [==============================] - 23s 963us/step - loss: 0.4045 - acc: 0.8027\n",
      "Epoch 40/100\n",
      "23948/23948 [==============================] - 23s 963us/step - loss: 0.3970 - acc: 0.8079\n",
      "Epoch 41/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3883 - acc: 0.8132\n",
      "Epoch 42/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3797 - acc: 0.8198\n",
      "Epoch 43/100\n",
      "23948/23948 [==============================] - 23s 970us/step - loss: 0.3769 - acc: 0.8202\n",
      "Epoch 44/100\n",
      "23948/23948 [==============================] - 24s 999us/step - loss: 0.3654 - acc: 0.8265\n",
      "Epoch 45/100\n",
      "23948/23948 [==============================] - 23s 964us/step - loss: 0.3606 - acc: 0.8288\n",
      "Epoch 46/100\n",
      "23948/23948 [==============================] - 23s 958us/step - loss: 0.3591 - acc: 0.8303\n",
      "Epoch 47/100\n",
      "23948/23948 [==============================] - 23s 961us/step - loss: 0.3501 - acc: 0.8361\n",
      "Epoch 48/100\n",
      "23948/23948 [==============================] - 23s 960us/step - loss: 0.3455 - acc: 0.8395\n",
      "Epoch 49/100\n",
      "23948/23948 [==============================] - 23s 967us/step - loss: 0.3333 - acc: 0.8450\n",
      "Epoch 50/100\n",
      "23948/23948 [==============================] - 23s 960us/step - loss: 0.3325 - acc: 0.8455\n",
      "Epoch 51/100\n",
      "23948/23948 [==============================] - 23s 962us/step - loss: 0.3242 - acc: 0.8510\n",
      "Epoch 52/100\n",
      "23948/23948 [==============================] - 23s 965us/step - loss: 0.3216 - acc: 0.8523\n",
      "Epoch 53/100\n",
      "23948/23948 [==============================] - 23s 961us/step - loss: 0.3141 - acc: 0.8582\n",
      "Epoch 54/100\n",
      "23948/23948 [==============================] - 23s 962us/step - loss: 0.3092 - acc: 0.8580\n",
      "Epoch 55/100\n",
      "23948/23948 [==============================] - 23s 962us/step - loss: 0.3047 - acc: 0.8611\n",
      "Epoch 56/100\n",
      "23948/23948 [==============================] - 23s 959us/step - loss: 0.2972 - acc: 0.8659\n",
      "Epoch 57/100\n",
      "23948/23948 [==============================] - 24s 984us/step - loss: 0.2985 - acc: 0.8668\n",
      "Epoch 58/100\n",
      "23948/23948 [==============================] - 24s 998us/step - loss: 0.2905 - acc: 0.8691\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23948/23948 [==============================] - 23s 961us/step - loss: 0.2863 - acc: 0.8720\n",
      "Epoch 60/100\n",
      "23948/23948 [==============================] - 23s 952us/step - loss: 0.2829 - acc: 0.8734\n",
      "Epoch 61/100\n",
      "23948/23948 [==============================] - 23s 958us/step - loss: 0.2768 - acc: 0.8782\n",
      "Epoch 62/100\n",
      "23948/23948 [==============================] - 23s 950us/step - loss: 0.2692 - acc: 0.8826\n",
      "Epoch 63/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2671 - acc: 0.8822\n",
      "Epoch 64/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2637 - acc: 0.8825\n",
      "Epoch 65/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2533 - acc: 0.8909\n",
      "Epoch 66/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2526 - acc: 0.8879: 0s - loss: 0.2527 - acc: 0.88\n",
      "Epoch 67/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2510 - acc: 0.8891\n",
      "Epoch 68/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2472 - acc: 0.8942\n",
      "Epoch 69/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2462 - acc: 0.8936\n",
      "Epoch 70/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2390 - acc: 0.8962\n",
      "Epoch 71/100\n",
      "23948/23948 [==============================] - 23s 969us/step - loss: 0.2385 - acc: 0.8961\n",
      "Epoch 72/100\n",
      "23948/23948 [==============================] - 23s 971us/step - loss: 0.2333 - acc: 0.9010\n",
      "Epoch 73/100\n",
      "23948/23948 [==============================] - 23s 969us/step - loss: 0.2281 - acc: 0.9011\n",
      "Epoch 74/100\n",
      "23948/23948 [==============================] - 23s 966us/step - loss: 0.2246 - acc: 0.9035\n",
      "Epoch 75/100\n",
      "23948/23948 [==============================] - 24s 987us/step - loss: 0.2215 - acc: 0.9051\n",
      "Epoch 76/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2183 - acc: 0.9061\n",
      "Epoch 77/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2178 - acc: 0.9075\n",
      "Epoch 78/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2135 - acc: 0.9101\n",
      "Epoch 79/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2073 - acc: 0.9131\n",
      "Epoch 80/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2027 - acc: 0.9157\n",
      "Epoch 81/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2067 - acc: 0.9127\n",
      "Epoch 82/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1976 - acc: 0.9173\n",
      "Epoch 83/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1958 - acc: 0.9165\n",
      "Epoch 84/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2009 - acc: 0.9169\n",
      "Epoch 85/100\n",
      "23948/23948 [==============================] - 31s 1ms/step - loss: 0.1944 - acc: 0.9203\n",
      "Epoch 86/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.1828 - acc: 0.9258\n",
      "Epoch 87/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1845 - acc: 0.9219\n",
      "Epoch 88/100\n",
      "23948/23948 [==============================] - 24s 998us/step - loss: 0.1855 - acc: 0.9231\n",
      "Epoch 89/100\n",
      "23948/23948 [==============================] - 24s 991us/step - loss: 0.1888 - acc: 0.9233\n",
      "Epoch 90/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1865 - acc: 0.9215\n",
      "Epoch 91/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.1767 - acc: 0.9287\n",
      "Epoch 92/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1777 - acc: 0.9286\n",
      "Epoch 93/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.1730 - acc: 0.9283\n",
      "Epoch 94/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1669 - acc: 0.9335\n",
      "Epoch 95/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1742 - acc: 0.9275\n",
      "Epoch 96/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1681 - acc: 0.9324\n",
      "Epoch 97/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1649 - acc: 0.9334\n",
      "Epoch 98/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1610 - acc: 0.9340\n",
      "Epoch 99/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1644 - acc: 0.9354\n",
      "Epoch 100/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1564 - acc: 0.9346\n",
      "0.836842973302804\n",
      "0.8396779195688647\n",
      "2 fold\n",
      "Epoch 1/100\n",
      "23948/23948 [==============================] - 41s 2ms/step - loss: 0.6916 - acc: 0.5248\n",
      "Epoch 2/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.6909 - acc: 0.5253\n",
      "Epoch 3/100\n",
      "23948/23948 [==============================] - 31s 1ms/step - loss: 0.6895 - acc: 0.5296\n",
      "Epoch 4/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.6879 - acc: 0.5358\n",
      "Epoch 5/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.6862 - acc: 0.5354\n",
      "Epoch 6/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6852 - acc: 0.5408\n",
      "Epoch 7/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6837 - acc: 0.5415\n",
      "Epoch 8/100\n",
      "23948/23948 [==============================] - 33s 1ms/step - loss: 0.6826 - acc: 0.5456\n",
      "Epoch 9/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.6811 - acc: 0.5473\n",
      "Epoch 10/100\n",
      "23948/23948 [==============================] - 33s 1ms/step - loss: 0.6785 - acc: 0.5526\n",
      "Epoch 11/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6752 - acc: 0.5562\n",
      "Epoch 12/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.6722 - acc: 0.5645\n",
      "Epoch 13/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6679 - acc: 0.5698\n",
      "Epoch 14/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6613 - acc: 0.5816\n",
      "Epoch 15/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6556 - acc: 0.5919\n",
      "Epoch 16/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6482 - acc: 0.6002\n",
      "Epoch 17/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6381 - acc: 0.6119\n",
      "Epoch 18/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6291 - acc: 0.6243\n",
      "Epoch 19/100\n",
      "23948/23948 [==============================] - 23s 976us/step - loss: 0.6192 - acc: 0.6290\n",
      "Epoch 20/100\n",
      "23948/23948 [==============================] - 23s 975us/step - loss: 0.6100 - acc: 0.6401\n",
      "Epoch 21/100\n",
      "23948/23948 [==============================] - 23s 970us/step - loss: 0.5995 - acc: 0.6525\n",
      "Epoch 22/100\n",
      "23948/23948 [==============================] - 23s 976us/step - loss: 0.5876 - acc: 0.6623\n",
      "Epoch 23/100\n",
      "23948/23948 [==============================] - 23s 967us/step - loss: 0.5771 - acc: 0.6714\n",
      "Epoch 24/100\n",
      "23948/23948 [==============================] - 23s 970us/step - loss: 0.5662 - acc: 0.6835\n",
      "Epoch 25/100\n",
      "23948/23948 [==============================] - 23s 964us/step - loss: 0.5558 - acc: 0.6921\n",
      "Epoch 26/100\n",
      "23948/23948 [==============================] - 23s 959us/step - loss: 0.5430 - acc: 0.7017\n",
      "Epoch 27/100\n",
      "23948/23948 [==============================] - 23s 966us/step - loss: 0.5355 - acc: 0.7052\n",
      "Epoch 28/100\n",
      "23948/23948 [==============================] - 24s 986us/step - loss: 0.5243 - acc: 0.7181\n",
      "Epoch 29/100\n",
      "23948/23948 [==============================] - 23s 976us/step - loss: 0.5133 - acc: 0.7256\n",
      "Epoch 30/100\n",
      "23948/23948 [==============================] - 23s 971us/step - loss: 0.5051 - acc: 0.7351\n",
      "Epoch 31/100\n",
      "23948/23948 [==============================] - 24s 990us/step - loss: 0.4937 - acc: 0.7382\n",
      "Epoch 32/100\n",
      "23948/23948 [==============================] - 24s 999us/step - loss: 0.4811 - acc: 0.7528\n",
      "Epoch 33/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4716 - acc: 0.7578\n",
      "Epoch 34/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4624 - acc: 0.7644\n",
      "Epoch 35/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4534 - acc: 0.7716\n",
      "Epoch 36/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4437 - acc: 0.7781\n",
      "Epoch 37/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.4373 - acc: 0.7828\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.4291 - acc: 0.7869\n",
      "Epoch 39/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.4188 - acc: 0.7920\n",
      "Epoch 40/100\n",
      "23948/23948 [==============================] - 31s 1ms/step - loss: 0.4130 - acc: 0.7996\n",
      "Epoch 41/100\n",
      "23948/23948 [==============================] - 33s 1ms/step - loss: 0.4022 - acc: 0.8032\n",
      "Epoch 42/100\n",
      "23948/23948 [==============================] - 31s 1ms/step - loss: 0.3946 - acc: 0.8083\n",
      "Epoch 43/100\n",
      "23948/23948 [==============================] - 33s 1ms/step - loss: 0.3876 - acc: 0.8153\n",
      "Epoch 44/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.3795 - acc: 0.8172\n",
      "Epoch 45/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.3721 - acc: 0.8232\n",
      "Epoch 46/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3632 - acc: 0.8277\n",
      "Epoch 47/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3624 - acc: 0.8289\n",
      "Epoch 48/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3490 - acc: 0.8387\n",
      "Epoch 49/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3492 - acc: 0.8355\n",
      "Epoch 50/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3401 - acc: 0.8420\n",
      "Epoch 51/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.3357 - acc: 0.8440\n",
      "Epoch 52/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3248 - acc: 0.8503\n",
      "Epoch 53/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3191 - acc: 0.8537\n",
      "Epoch 54/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3125 - acc: 0.8577\n",
      "Epoch 55/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.3086 - acc: 0.8598\n",
      "Epoch 56/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.3054 - acc: 0.8627\n",
      "Epoch 57/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2986 - acc: 0.8659\n",
      "Epoch 58/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2948 - acc: 0.8671\n",
      "Epoch 59/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2860 - acc: 0.8723\n",
      "Epoch 60/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2833 - acc: 0.8729\n",
      "Epoch 61/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.2802 - acc: 0.8753\n",
      "Epoch 62/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2749 - acc: 0.8778\n",
      "Epoch 63/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2710 - acc: 0.8808\n",
      "Epoch 64/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2636 - acc: 0.8845\n",
      "Epoch 65/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2632 - acc: 0.8846\n",
      "Epoch 66/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2528 - acc: 0.8881\n",
      "Epoch 67/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2534 - acc: 0.8901\n",
      "Epoch 68/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2511 - acc: 0.8918\n",
      "Epoch 69/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2433 - acc: 0.8932\n",
      "Epoch 70/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2408 - acc: 0.8954\n",
      "Epoch 71/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2356 - acc: 0.8987\n",
      "Epoch 72/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2330 - acc: 0.9025\n",
      "Epoch 73/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2342 - acc: 0.8995\n",
      "Epoch 74/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2249 - acc: 0.9047\n",
      "Epoch 75/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2247 - acc: 0.9020\n",
      "Epoch 76/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2139 - acc: 0.9096\n",
      "Epoch 77/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2132 - acc: 0.9111\n",
      "Epoch 78/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2197 - acc: 0.9065\n",
      "Epoch 79/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2088 - acc: 0.9145\n",
      "Epoch 80/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2017 - acc: 0.9170\n",
      "Epoch 81/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2002 - acc: 0.9141\n",
      "Epoch 82/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2026 - acc: 0.9144\n",
      "Epoch 83/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1994 - acc: 0.9176\n",
      "Epoch 84/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1928 - acc: 0.9189\n",
      "Epoch 85/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1926 - acc: 0.9192\n",
      "Epoch 86/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1858 - acc: 0.9218\n",
      "Epoch 87/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.1838 - acc: 0.9243\n",
      "Epoch 88/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1868 - acc: 0.9230\n",
      "Epoch 89/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.1820 - acc: 0.9247\n",
      "Epoch 90/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1795 - acc: 0.9245\n",
      "Epoch 91/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1789 - acc: 0.9278\n",
      "Epoch 92/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1808 - acc: 0.9269\n",
      "Epoch 93/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1713 - acc: 0.9314\n",
      "Epoch 94/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1667 - acc: 0.9324\n",
      "Epoch 95/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1663 - acc: 0.9326\n",
      "Epoch 96/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1652 - acc: 0.9321\n",
      "Epoch 97/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1633 - acc: 0.9324\n",
      "Epoch 98/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1650 - acc: 0.9335\n",
      "Epoch 99/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1608 - acc: 0.9357\n",
      "Epoch 100/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1630 - acc: 0.9334\n",
      "0.842871121606954\n",
      "0.8386901433001895\n",
      "3 fold\n",
      "Epoch 1/100\n",
      "23948/23948 [==============================] - 42s 2ms/step - loss: 0.6916 - acc: 0.5230\n",
      "Epoch 2/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.6908 - acc: 0.5245\n",
      "Epoch 3/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.6882 - acc: 0.5325\n",
      "Epoch 4/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6877 - acc: 0.5339\n",
      "Epoch 5/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6859 - acc: 0.5376\n",
      "Epoch 6/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6841 - acc: 0.5402\n",
      "Epoch 7/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.6830 - acc: 0.5365\n",
      "Epoch 8/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6816 - acc: 0.5431\n",
      "Epoch 9/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6787 - acc: 0.5495\n",
      "Epoch 10/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6770 - acc: 0.5456\n",
      "Epoch 11/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6752 - acc: 0.5532\n",
      "Epoch 12/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.6718 - acc: 0.5612\n",
      "Epoch 13/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6699 - acc: 0.5671\n",
      "Epoch 14/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6654 - acc: 0.5699\n",
      "Epoch 15/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6608 - acc: 0.5796\n",
      "Epoch 16/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6535 - acc: 0.5881\n",
      "Epoch 17/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6485 - acc: 0.5970\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.6410 - acc: 0.6046\n",
      "Epoch 19/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6326 - acc: 0.6155\n",
      "Epoch 20/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6252 - acc: 0.6229\n",
      "Epoch 21/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.6153 - acc: 0.6357\n",
      "Epoch 22/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6064 - acc: 0.6446\n",
      "Epoch 23/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.5960 - acc: 0.6576\n",
      "Epoch 24/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.5852 - acc: 0.6695\n",
      "Epoch 25/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.5784 - acc: 0.6721\n",
      "Epoch 26/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5658 - acc: 0.6847\n",
      "Epoch 27/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.5598 - acc: 0.6913\n",
      "Epoch 28/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5493 - acc: 0.7018\n",
      "Epoch 29/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.5388 - acc: 0.7089\n",
      "Epoch 30/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.5306 - acc: 0.7137\n",
      "Epoch 31/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.5207 - acc: 0.7233\n",
      "Epoch 32/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.5133 - acc: 0.7295\n",
      "Epoch 33/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.5017 - acc: 0.7338\n",
      "Epoch 34/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.4923 - acc: 0.7431\n",
      "Epoch 35/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.4888 - acc: 0.7474\n",
      "Epoch 36/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.4756 - acc: 0.7568\n",
      "Epoch 37/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.4706 - acc: 0.7601\n",
      "Epoch 38/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.4598 - acc: 0.7653\n",
      "Epoch 39/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.4502 - acc: 0.7759\n",
      "Epoch 40/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.4440 - acc: 0.7768\n",
      "Epoch 41/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.4362 - acc: 0.7840\n",
      "Epoch 42/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.4288 - acc: 0.7878\n",
      "Epoch 43/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.4215 - acc: 0.7960\n",
      "Epoch 44/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.4140 - acc: 0.7996\n",
      "Epoch 45/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.4092 - acc: 0.8007\n",
      "Epoch 46/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.4023 - acc: 0.8055\n",
      "Epoch 47/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.3967 - acc: 0.8079\n",
      "Epoch 48/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.3878 - acc: 0.8119\n",
      "Epoch 49/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3839 - acc: 0.8146\n",
      "Epoch 50/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3734 - acc: 0.8208\n",
      "Epoch 51/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3716 - acc: 0.8248\n",
      "Epoch 52/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.3645 - acc: 0.8274\n",
      "Epoch 53/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3551 - acc: 0.8332\n",
      "Epoch 54/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3492 - acc: 0.8349\n",
      "Epoch 55/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.3441 - acc: 0.8399: 2s -\n",
      "Epoch 56/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3426 - acc: 0.8401\n",
      "Epoch 57/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3377 - acc: 0.8463\n",
      "Epoch 58/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3301 - acc: 0.8468\n",
      "Epoch 59/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3251 - acc: 0.8491\n",
      "Epoch 60/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3157 - acc: 0.8545\n",
      "Epoch 61/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3123 - acc: 0.8566\n",
      "Epoch 62/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3158 - acc: 0.8561\n",
      "Epoch 63/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3041 - acc: 0.8621\n",
      "Epoch 64/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2979 - acc: 0.8645\n",
      "Epoch 65/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2979 - acc: 0.8645\n",
      "Epoch 66/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2935 - acc: 0.8690\n",
      "Epoch 67/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2890 - acc: 0.8696\n",
      "Epoch 68/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2805 - acc: 0.8756\n",
      "Epoch 69/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2773 - acc: 0.8757\n",
      "Epoch 70/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2687 - acc: 0.8812\n",
      "Epoch 71/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2686 - acc: 0.8795\n",
      "Epoch 72/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2685 - acc: 0.8793\n",
      "Epoch 73/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2591 - acc: 0.8855\n",
      "Epoch 74/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2582 - acc: 0.8878\n",
      "Epoch 75/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2584 - acc: 0.8868\n",
      "Epoch 76/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2502 - acc: 0.8929\n",
      "Epoch 77/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2516 - acc: 0.8921\n",
      "Epoch 78/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2445 - acc: 0.8951\n",
      "Epoch 79/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2427 - acc: 0.8936\n",
      "Epoch 80/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2405 - acc: 0.8953\n",
      "Epoch 81/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2373 - acc: 0.8969\n",
      "Epoch 82/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2304 - acc: 0.9023\n",
      "Epoch 83/100\n",
      "23948/23948 [==============================] - 24s 998us/step - loss: 0.2263 - acc: 0.9029\n",
      "Epoch 84/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2210 - acc: 0.9048\n",
      "Epoch 85/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2219 - acc: 0.9060\n",
      "Epoch 86/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2132 - acc: 0.9131\n",
      "Epoch 87/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2214 - acc: 0.9036\n",
      "Epoch 88/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2107 - acc: 0.9118\n",
      "Epoch 89/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.2093 - acc: 0.9127\n",
      "Epoch 90/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2059 - acc: 0.9114\n",
      "Epoch 91/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2064 - acc: 0.9136\n",
      "Epoch 92/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2012 - acc: 0.9166\n",
      "Epoch 93/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.1951 - acc: 0.9193\n",
      "Epoch 94/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1991 - acc: 0.9176\n",
      "Epoch 95/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1881 - acc: 0.9238\n",
      "Epoch 96/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1882 - acc: 0.9217\n",
      "Epoch 97/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1842 - acc: 0.9252\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1878 - acc: 0.9214\n",
      "Epoch 99/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1850 - acc: 0.9250\n",
      "Epoch 100/100\n",
      "23948/23948 [==============================] - 23s 980us/step - loss: 0.1749 - acc: 0.9303\n",
      "0.8324269669047124\n",
      "0.826487474851652\n",
      "4 fold\n",
      "Epoch 1/100\n",
      "23948/23948 [==============================] - 40s 2ms/step - loss: 0.6915 - acc: 0.5186\n",
      "Epoch 2/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6909 - acc: 0.5254\n",
      "Epoch 3/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.6881 - acc: 0.5332\n",
      "Epoch 4/100\n",
      "23948/23948 [==============================] - 33s 1ms/step - loss: 0.6874 - acc: 0.5372\n",
      "Epoch 5/100\n",
      "23948/23948 [==============================] - 32s 1ms/step - loss: 0.6859 - acc: 0.5371\n",
      "Epoch 6/100\n",
      "23948/23948 [==============================] - 32s 1ms/step - loss: 0.6840 - acc: 0.5447\n",
      "Epoch 7/100\n",
      "23948/23948 [==============================] - 31s 1ms/step - loss: 0.6823 - acc: 0.5464\n",
      "Epoch 8/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.6795 - acc: 0.5527\n",
      "Epoch 9/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.6772 - acc: 0.5538\n",
      "Epoch 10/100\n",
      "23948/23948 [==============================] - 24s 994us/step - loss: 0.6735 - acc: 0.5620\n",
      "Epoch 11/100\n",
      "23948/23948 [==============================] - 23s 980us/step - loss: 0.6703 - acc: 0.5612\n",
      "Epoch 12/100\n",
      "23948/23948 [==============================] - 24s 987us/step - loss: 0.6669 - acc: 0.5679\n",
      "Epoch 13/100\n",
      "23948/23948 [==============================] - 24s 985us/step - loss: 0.6609 - acc: 0.5738\n",
      "Epoch 14/100\n",
      "23948/23948 [==============================] - 23s 976us/step - loss: 0.6545 - acc: 0.5837\n",
      "Epoch 15/100\n",
      "23948/23948 [==============================] - 23s 979us/step - loss: 0.6495 - acc: 0.5934\n",
      "Epoch 16/100\n",
      "23948/23948 [==============================] - 23s 979us/step - loss: 0.6409 - acc: 0.6047\n",
      "Epoch 17/100\n",
      "23948/23948 [==============================] - 24s 988us/step - loss: 0.6344 - acc: 0.6174\n",
      "Epoch 18/100\n",
      "23948/23948 [==============================] - 24s 985us/step - loss: 0.6243 - acc: 0.6300\n",
      "Epoch 19/100\n",
      "23948/23948 [==============================] - 24s 985us/step - loss: 0.6155 - acc: 0.6361\n",
      "Epoch 20/100\n",
      "23948/23948 [==============================] - 24s 989us/step - loss: 0.6079 - acc: 0.6467\n",
      "Epoch 21/100\n",
      "23948/23948 [==============================] - 24s 983us/step - loss: 0.5928 - acc: 0.6601\n",
      "Epoch 22/100\n",
      "23948/23948 [==============================] - 24s 992us/step - loss: 0.5840 - acc: 0.6690\n",
      "Epoch 23/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.5729 - acc: 0.6793\n",
      "Epoch 24/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.5642 - acc: 0.6854\n",
      "Epoch 25/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.5524 - acc: 0.6955\n",
      "Epoch 26/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.5428 - acc: 0.7031\n",
      "Epoch 27/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.5308 - acc: 0.7137\n",
      "Epoch 28/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.5205 - acc: 0.7214\n",
      "Epoch 29/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.5119 - acc: 0.7280\n",
      "Epoch 30/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.5006 - acc: 0.7395\n",
      "Epoch 31/100\n",
      "23948/23948 [==============================] - 32s 1ms/step - loss: 0.4906 - acc: 0.7430\n",
      "Epoch 32/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.4835 - acc: 0.7485\n",
      "Epoch 33/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.4757 - acc: 0.7555\n",
      "Epoch 34/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.4637 - acc: 0.7663\n",
      "Epoch 35/100\n",
      "23948/23948 [==============================] - 33s 1ms/step - loss: 0.4576 - acc: 0.7692\n",
      "Epoch 36/100\n",
      "23948/23948 [==============================] - 34s 1ms/step - loss: 0.4439 - acc: 0.7760\n",
      "Epoch 37/100\n",
      "23948/23948 [==============================] - 31s 1ms/step - loss: 0.4386 - acc: 0.7790\n",
      "Epoch 38/100\n",
      "23948/23948 [==============================] - 33s 1ms/step - loss: 0.4289 - acc: 0.7863\n",
      "Epoch 39/100\n",
      "23948/23948 [==============================] - 31s 1ms/step - loss: 0.4200 - acc: 0.7960\n",
      "Epoch 40/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.4157 - acc: 0.7974\n",
      "Epoch 41/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.4023 - acc: 0.8032\n",
      "Epoch 42/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.3969 - acc: 0.8044\n",
      "Epoch 43/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3921 - acc: 0.8128\n",
      "Epoch 44/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3851 - acc: 0.8150\n",
      "Epoch 45/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.3776 - acc: 0.8169\n",
      "Epoch 46/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.3689 - acc: 0.8237\n",
      "Epoch 47/100\n",
      "23948/23948 [==============================] - 32s 1ms/step - loss: 0.3659 - acc: 0.8272\n",
      "Epoch 48/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.3577 - acc: 0.8327\n",
      "Epoch 49/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3535 - acc: 0.8343\n",
      "Epoch 50/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3427 - acc: 0.8399\n",
      "Epoch 51/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.3399 - acc: 0.8425\n",
      "Epoch 52/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3313 - acc: 0.8467\n",
      "Epoch 53/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3284 - acc: 0.8507\n",
      "Epoch 54/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3201 - acc: 0.8527\n",
      "Epoch 55/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3143 - acc: 0.8550\n",
      "Epoch 56/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3086 - acc: 0.8594\n",
      "Epoch 57/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.3022 - acc: 0.8608\n",
      "Epoch 58/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2988 - acc: 0.8652\n",
      "Epoch 59/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2963 - acc: 0.8656\n",
      "Epoch 60/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2888 - acc: 0.8682\n",
      "Epoch 61/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2827 - acc: 0.8721\n",
      "Epoch 62/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2775 - acc: 0.8757\n",
      "Epoch 63/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.2787 - acc: 0.8783\n",
      "Epoch 64/100\n",
      "23948/23948 [==============================] - 26s 1ms/step - loss: 0.2700 - acc: 0.8827\n",
      "Epoch 65/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2670 - acc: 0.8802\n",
      "Epoch 66/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2594 - acc: 0.8831\n",
      "Epoch 67/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2596 - acc: 0.8857\n",
      "Epoch 68/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2523 - acc: 0.8890\n",
      "Epoch 69/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.2512 - acc: 0.8895\n",
      "Epoch 70/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2450 - acc: 0.8930\n",
      "Epoch 71/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2478 - acc: 0.8937\n",
      "Epoch 72/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2399 - acc: 0.8957\n",
      "Epoch 73/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2364 - acc: 0.8987\n",
      "Epoch 74/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2374 - acc: 0.8960\n",
      "Epoch 75/100\n",
      "23948/23948 [==============================] - 30s 1ms/step - loss: 0.2306 - acc: 0.9015\n",
      "Epoch 76/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.2295 - acc: 0.9001\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2248 - acc: 0.9034\n",
      "Epoch 78/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2191 - acc: 0.9068\n",
      "Epoch 79/100\n",
      "23948/23948 [==============================] - 29s 1ms/step - loss: 0.2171 - acc: 0.9078\n",
      "Epoch 80/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2105 - acc: 0.9097\n",
      "Epoch 81/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.2153 - acc: 0.9095\n",
      "Epoch 82/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1998 - acc: 0.9162\n",
      "Epoch 83/100\n",
      "23948/23948 [==============================] - 28s 1ms/step - loss: 0.2020 - acc: 0.9151\n",
      "Epoch 84/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1992 - acc: 0.9175\n",
      "Epoch 85/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1971 - acc: 0.9192\n",
      "Epoch 86/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1906 - acc: 0.9232\n",
      "Epoch 87/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1910 - acc: 0.9216\n",
      "Epoch 88/100\n",
      "23948/23948 [==============================] - 27s 1ms/step - loss: 0.1850 - acc: 0.9227\n",
      "Epoch 89/100\n",
      "23948/23948 [==============================] - 25s 1ms/step - loss: 0.1937 - acc: 0.9195\n",
      "Epoch 90/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1849 - acc: 0.9229\n",
      "Epoch 91/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1852 - acc: 0.9238\n",
      "Epoch 92/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1796 - acc: 0.9255\n",
      "Epoch 93/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1790 - acc: 0.9259\n",
      "Epoch 94/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1746 - acc: 0.9271\n",
      "Epoch 95/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1750 - acc: 0.9287\n",
      "Epoch 96/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1740 - acc: 0.9292\n",
      "Epoch 97/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1692 - acc: 0.9327\n",
      "Epoch 98/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1691 - acc: 0.9316\n",
      "Epoch 99/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1627 - acc: 0.9360\n",
      "Epoch 100/100\n",
      "23948/23948 [==============================] - 24s 1ms/step - loss: 0.1678 - acc: 0.9319\n",
      "0.8313934412654277\n",
      "0.8217416093490119\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "df_yanz=pd.DataFrame()\n",
    "df_jieguo=pd.DataFrame()\n",
    "for train,test in kf.split(xtrain):\n",
    "    a = []\n",
    "    b= []\n",
    "    X_train, X_valid= xtrain[train,:], xtrain[test,:]\n",
    "    y_train, y_valid = ytrain[train,:], ytrain[test,:]\n",
    "    print(i, 'fold')\n",
    "    regressor1 = Sequential()\n",
    "    regressor1.add(LSTM(units = 70, return_sequences = True, input_shape = (xtrain.shape[1], 8)))\n",
    "    regressor1.add(Dropout(0.2))\n",
    "    regressor1.add(LSTM(units = 70, return_sequences = True))\n",
    "    regressor1.add(Dropout(0.2))\n",
    "    regressor1.add(LSTM(units = 70,return_sequences = True))\n",
    "    regressor1.add(Dropout(0.2))\n",
    "    regressor1.add(LSTM(units = 70))\n",
    "    regressor1.add(Dropout(0.2))\n",
    "    regressor1.add(layers.Dense(1, activation='sigmoid'))\n",
    "    regressor1.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    regressor1.fit(X_train,y_train, epochs = 100, batch_size = 80)\n",
    "    joblib.dump(regressor1, './1lstm%s.model' % str(i))\n",
    "    predicted_stock_price1 = regressor1.predict(X_valid)\n",
    "    fpr1, tpr1, thresholds1 = roc_curve(y_valid,predicted_stock_price1, pos_label=1)\n",
    "    a=auc(fpr1, tpr1)\n",
    "    print(a)\n",
    "    predicted_stock_price2 = regressor1.predict(xtest)\n",
    "    fpr2, tpr2, thresholds2 = roc_curve(ytest, predicted_stock_price2, pos_label=1)\n",
    "    b=auc(fpr2, tpr2)\n",
    "    print(b)\n",
    "#     df_yanz=df_yanz+pd.DataFrame(predicted_stock_price2)\n",
    "#     df_pr=pd.DataFrame()\n",
    "#     for arr in colums:\n",
    "#         df4 = df_final.loc[df_final['ts_code']==arr]\n",
    "#         dataset4=df4.values\n",
    "#         x1=dataset2[0:10,3:11].tolist()\n",
    "#         x1=np.array(x1)\n",
    "#         x1=np.reshape(x1, (1,x1.shape[0],x1.shape[1]))\n",
    "#         ytest1=regressor1.predict(x1)\n",
    "#         y_p=pd.DataFrame(ytest1)\n",
    "#         y_p=y_p.T\n",
    "#         y_p['ts_code']=arr\n",
    "#         y_p['trade_date']=[20190605,20190606,20190607,20190610,20190611]\n",
    "#     df_pr = pd.concat([df_pr,y_p])\n",
    "# # df_pr=df_me.merge(df_pr,how='left',on='name')\n",
    "#     df_pr.columns=['i','ts_code','trade_date']\n",
    "#     df_pr=df_pr[['ts_code','trade_date','i']]\n",
    "#     df_jieguo['ts_code']=df_pr['ts_code']\n",
    "#     df_jieguo['trade_date']=df_pr['trade_date']\n",
    "#     df_jieguo['i']=df_pr['i']\n",
    "#     joblib.dump(regressor1,'./lstm%s.model'%str(i))\n",
    "    i=i+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8783419486414135"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor1=joblib.load('./1lstm0.model')\n",
    "regressor2=joblib.load('./1lstm1.model')\n",
    "regressor3=joblib.load('./1lstm2.model')\n",
    "regressor4=joblib.load('./1lstm3.model')\n",
    "regressor5=joblib.load('./1lstm4.model')\n",
    "predicted_stock_price3 = regressor1.predict(xtest)\n",
    "predicted_stock_price4 = regressor2.predict(xtest)\n",
    "predicted_stock_price5 = regressor3.predict(xtest)\n",
    "predicted_stock_price6= regressor4.predict(xtest)\n",
    "predicted_stock_price7 = regressor5.predict(xtest)\n",
    "y=(predicted_stock_price3+predicted_stock_price4+predicted_stock_price5+predicted_stock_price6+predicted_stock_price7)/5\n",
    "fpr3, tpr3, thresholds3 = roc_curve(ytest, y, pos_label=1)\n",
    "auc(fpr3, tpr3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Psj0EPU4XrN"
   },
   "outputs": [],
   "source": [
    "df_pr=pd.DataFrame()\n",
    "i=0\n",
    "range_index = (df_test4.trade_date > 20190521)\n",
    "df_final = df_test4[range_index]\n",
    "for i in range(5):\n",
    "    model=joblib.load('./lstm%s.model'%str(i))\n",
    "    for arr in colums:\n",
    "        df4 = df_final.loc[df_final['ts_code']==arr]\n",
    "        dataset4=df4.values\n",
    "        x1=dataset2[0:10,3:11].tolist()\n",
    "        x1=np.array(x1)\n",
    "        x1=np.reshape(x1, (1,x1.shape[0],x1.shape[1]))\n",
    "        ytest1= model.predict(x1)\n",
    "        y_p=pd.DataFrame(ytest1)\n",
    "        y_p=y_p.T\n",
    "        y_p['ts_code']=arr\n",
    "        y_p['trade_date']=[20190605,20190606,20190607,20190610,20190611]\n",
    "y_p\n",
    "#     df_pr = pd.concat([df_pr,y_p])\n",
    "# # df_pr=df_me.merge(df_pr,how='left',on='name')\n",
    "#     df_pr.columns=['w','i','ts_code','trade_date']\n",
    "#     df_pr=df_pr[['ts_code','trade_date','i']]\n",
    "#     df_jieguo['ts_code']=df_pr['ts_code']\n",
    "#     df_jieguo['trade_date']=df_pr['trade_date']\n",
    "#     df_jieguo['i']=df_pr['i']\n",
    "#     i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QE621kXX55FR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qoqDrHwX5wUJ"
   },
   "source": [
    "# 新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vy98Vht5wUK"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'./TRAINSET_STOCK.csv')\n",
    "df_add = pd.read_csv(r'./20190506_STOCK.csv')\n",
    "df_test = pd.read_csv(r'./20190514_STOCK.csv')\n",
    "df1 = pd.concat([df1,df_add,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "woTptZ7Q4MKR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "CwBRWOcgnAw7",
    "outputId": "f0606309-a225-42a7-efac-e892060cf77c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1152</th>\n",
       "      <th>2304</th>\n",
       "      <th>3456</th>\n",
       "      <th>3656</th>\n",
       "      <th>4608</th>\n",
       "      <th>5760</th>\n",
       "      <th>6912</th>\n",
       "      <th>8064</th>\n",
       "      <th>9216</th>\n",
       "      <th>10368</th>\n",
       "      <th>11520</th>\n",
       "      <th>12672</th>\n",
       "      <th>13824</th>\n",
       "      <th>14976</th>\n",
       "      <th>16128</th>\n",
       "      <th>17280</th>\n",
       "      <th>17480</th>\n",
       "      <th>18432</th>\n",
       "      <th>19584</th>\n",
       "      <th>20736</th>\n",
       "      <th>21888</th>\n",
       "      <th>23040</th>\n",
       "      <th>24192</th>\n",
       "      <th>25344</th>\n",
       "      <th>26496</th>\n",
       "      <th>27648</th>\n",
       "      <th>28800</th>\n",
       "      <th>29952</th>\n",
       "      <th>31104</th>\n",
       "      <th>32256</th>\n",
       "      <th>33408</th>\n",
       "      <th>34560</th>\n",
       "      <th>35712</th>\n",
       "      <th>36864</th>\n",
       "      <th>38016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>采掘</td>\n",
       "      <td>化工</td>\n",
       "      <td>黑色金属</td>\n",
       "      <td>钢铁</td>\n",
       "      <td>有色金属</td>\n",
       "      <td>电子</td>\n",
       "      <td>家用电器</td>\n",
       "      <td>食品饮料</td>\n",
       "      <td>纺织服装</td>\n",
       "      <td>轻工制造</td>\n",
       "      <td>医药生物</td>\n",
       "      <td>公用事业</td>\n",
       "      <td>交通运输</td>\n",
       "      <td>房地产</td>\n",
       "      <td>商业贸易</td>\n",
       "      <td>餐饮旅游</td>\n",
       "      <td>休闲服务</td>\n",
       "      <td>综合</td>\n",
       "      <td>申万制造</td>\n",
       "      <td>申万消费</td>\n",
       "      <td>申万投资</td>\n",
       "      <td>申万服务</td>\n",
       "      <td>申万300指数</td>\n",
       "      <td>建筑材料</td>\n",
       "      <td>建筑装饰</td>\n",
       "      <td>电气设备</td>\n",
       "      <td>国防军工</td>\n",
       "      <td>计算机</td>\n",
       "      <td>传媒</td>\n",
       "      <td>通信</td>\n",
       "      <td>银行</td>\n",
       "      <td>非银金融</td>\n",
       "      <td>汽车</td>\n",
       "      <td>机械设备</td>\n",
       "      <td>交银装备</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts_code</th>\n",
       "      <td>801010</td>\n",
       "      <td>801020</td>\n",
       "      <td>801030</td>\n",
       "      <td>801040</td>\n",
       "      <td>801040</td>\n",
       "      <td>801050</td>\n",
       "      <td>801080</td>\n",
       "      <td>801110</td>\n",
       "      <td>801120</td>\n",
       "      <td>801130</td>\n",
       "      <td>801140</td>\n",
       "      <td>801150</td>\n",
       "      <td>801160</td>\n",
       "      <td>801170</td>\n",
       "      <td>801180</td>\n",
       "      <td>801200</td>\n",
       "      <td>801210</td>\n",
       "      <td>801210</td>\n",
       "      <td>801230</td>\n",
       "      <td>801250</td>\n",
       "      <td>801260</td>\n",
       "      <td>801270</td>\n",
       "      <td>801280</td>\n",
       "      <td>801300</td>\n",
       "      <td>801710</td>\n",
       "      <td>801720</td>\n",
       "      <td>801730</td>\n",
       "      <td>801740</td>\n",
       "      <td>801750</td>\n",
       "      <td>801760</td>\n",
       "      <td>801770</td>\n",
       "      <td>801780</td>\n",
       "      <td>801790</td>\n",
       "      <td>801880</td>\n",
       "      <td>801890</td>\n",
       "      <td>802600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1152    2304    3456   ...   34560   35712   36864   38016\n",
       "name       农林牧渔      采掘      化工    黑色金属  ...    非银金融      汽车    机械设备    交银装备\n",
       "ts_code  801010  801020  801030  801040  ...  801790  801880  801890  802600\n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df1[['name','ts_code']]\n",
    "df2 = df2.drop_duplicates(keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "5aBT8rQpq5oQ",
    "outputId": "badae5dd-a38d-47ae-edf8-684cd80752be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27077 entries, 0 to 112\n",
      "Data columns (total 4 columns):\n",
      "id         27077 non-null object\n",
      "date       27077 non-null int64\n",
      "title      27048 non-null object\n",
      "content    26915 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_news1 = pd.read_csv(r'./TRAINSET_NEWS.csv')\n",
    "df_news2= pd.read_csv(r'./20190506_NEWS.csv')\n",
    "df_news3= pd.read_csv(r'./20190514_NEWS.csv')\n",
    "df_news = pd.concat([df_news1,df_news2,df_news3])\n",
    "df_news.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMIF6YHBrwiO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QhyFLGZ5wUP"
   },
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Y4w2xzF5wUU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "time_step=10      #时间步\n",
    "rnn_unit=100      #hidden layer units\n",
    "batch_size=80     #每一批次训练多少个样例\n",
    "input_size=3      #输入层维度\n",
    "output_size=1     #输出层维度\n",
    "lr=0.0006 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PES9y7Tr5wUX"
   },
   "outputs": [],
   "source": [
    "# 训练集\n",
    "def get_train_data(batch_size=80,time_step=10,train_begin=0,train_end=900):\n",
    "  for arr in columns:\n",
    "    df1=df.loc[df['name']==arr]\n",
    "    df1=df1[['ts_code','trade_date','name','low','high','pct_change','vol','y']]\n",
    "    df1['vol_change'] = df['vol'].pct_change()\n",
    "    df1['low_change'] = df['low'].pct_change()\n",
    "    df1['high_change'] = df['high'].pct_change()\n",
    "    df1=df1[['pct_change','vol_change','high_change','low_change','y']]\n",
    "    df1= df1.dropna()\n",
    "    dataset=df1.values\n",
    "    batch_index=[]\n",
    "    data_train=dataset[train_begin:train_end]\n",
    "    normalized_train_data=(data_train-np.mean(data_train,axis=0))/np.std(data_train,axis=0)  #标准化\n",
    "    train_x,train_y=[],[]   #训练集x和y初定义\n",
    "    for i in range(len(normalized_train_data)-time_step):\n",
    "        if i % batch_size==0:\n",
    "            batch_index.append(i)\n",
    "            x=normalized_train_data[i:i+time_step,:5]\n",
    "            y=normalized_train_data[i:i+time_step,4,np.newaxis]\n",
    "            train_x.append(x.tolist())\n",
    "            train_y.append(y.tolist())\n",
    "    batch_index.append((len(normalized_train_data)-time_step))\n",
    "    return batch_index,train_x,train_y\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAZ4wvn5t8sD"
   },
   "outputs": [],
   "source": [
    "# 测试集\n",
    "def get_test_data(time_step=10,test_begin=900):\n",
    "  for arr in columns:\n",
    "    df1=df.loc[df['name']==arr]\n",
    "    df1=df1[['ts_code','trade_date','name','low','high','pct_change','vol','y']]\n",
    "    df1['vol_change'] = df['vol'].pct_change()\n",
    "    df1['low_change'] = df['low'].pct_change()\n",
    "    df1['high_change'] = df['high'].pct_change()\n",
    "    df1=df1[['pct_change','vol_change','high_change','low_change','y']]\n",
    "    df1= df1.dropna()\n",
    "    dataset=df1.values\n",
    "    data_test=dataset[test_begin:]\n",
    "    mean=np.mean(data_test,axis=0)\n",
    "    std=np.std(data_test,axis=0)\n",
    "    normalized_test_data=(data_test-mean)/std  #标准化\n",
    "    size=(len(normalized_test_data)+time_step-1)//time_step  #有size个sample \n",
    "    test_x,test_y=[],[]  \n",
    "    for i in range(size-1):\n",
    "        x=normalized_test_data[i*time_step:(i+1)*time_step,:5]\n",
    "        y=normalized_test_data[i*time_step:(i+1)*time_step,4]\n",
    "        test_x.append(x.tolist())\n",
    "        test_y.extend(y.tolist())\n",
    "    return mean,std,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAycDdYMuK4c"
   },
   "outputs": [],
   "source": [
    "# 模型搭建\n",
    "weights = {\n",
    "    'in': tf.Variable(tf.random_normal([input_size, rnn_unit])),\n",
    "    'out': tf.Variable(tf.random_normal([rnn_unit, 1 ]))\n",
    "}\n",
    "biases = {\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[rnn_unit, ])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[1, ]))\n",
    "}\n",
    "def lstm(X):     \n",
    "    time_step=10\n",
    "    w_in=weights['in']\n",
    "    b_in=biases['in']  \n",
    "    input=tf.reshape(X,[-1,input_size])  #需要将tensor转成2维进行计算，计算后的结果作为隐藏层的输入\n",
    "    input_rnn=tf.matmul(input,w_in)+b_in\n",
    "    input_rnn=tf.reshape(input_rnn,[-1,time_step,rnn_unit])  #将tensor转成3维，作为lstm cell的输入\n",
    "    cell=tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "    init_state=cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    output_rnn,final_states=tf.nn.dynamic_rnn(cell, input_rnn,initial_state=init_state, dtype=tf.float32)  #output_rnn是记录lstm每个输出节点的结果，final_states是最后一个cell的结果\n",
    "    output=tf.reshape(output_rnn,[-1,rnn_unit]) #作为输出层的输入\n",
    "    w_out=weights['out']\n",
    "    b_out=biases['out']\n",
    "    pred=tf.matmul(output,w_out)+b_out\n",
    "    return pred,final_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwDt36biuWX1"
   },
   "outputs": [],
   "source": [
    "def train_lstm(batch_size=80,time_step=10,train_begin=0,train_end=30000):\n",
    "    X=tf.placeholder(tf.float32, shape=[None,time_step,input_size])\n",
    "    Y=tf.placeholder(tf.float32, shape=[None,time_step,output_size])\n",
    "    batch_index,train_x,train_y=get_train_data(batch_size,time_step,train_begin,train_end)\n",
    "    pred,_=lstm(X)\n",
    "    #损失函数\n",
    "    loss=tf.reduce_mean(tf.square(tf.reshape(pred,[-1])-tf.reshape(Y, [-1])))\n",
    "    train_op=tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    saver=tf.train.Saver(tf.global_variables(),max_to_keep=15)\n",
    "    module_file = tf.train.latest_checkpoint()    \n",
    "    with tf.Session() as sess:\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, module_file)\n",
    "        #重复训练2000次\n",
    "        for i in range(2000):\n",
    "            for step in range(len(batch_index)-1):\n",
    "                _,loss_=sess.run([train_op,loss],feed_dict={X:train_x[batch_index[step]:batch_index[step+1]],Y:train_y[batch_index[step]:batch_index[step+1]]})\n",
    "            print(i,loss_)\n",
    "            if i % 200==0:\n",
    "                print(\"保存模型：\",saver.save(sess,'stock2.model',global_step=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BI6Foo891rww"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "def layer(inputs,input_dim,output_dim,activation=None):\n",
    "  with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weights'):\n",
    "       W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    with tf.name_scope('biases'):\n",
    "       b = tf.Variable(tf.random_normal([1, output_dim])+0.1)\n",
    "    with tf.name_scope('Wx_plus_b'):\n",
    "       XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2BtxTbER6hk"
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "  xs= tf.placeholder(tf.float32, [None,80],name='input_in')\n",
    "  ys=tf.placeholder(tf.float32, [None,5],name='intput_out')\n",
    "l1=layer(xs,80,100,activation=tf.nn.relu)\n",
    "prediction = layer(l1, 100, 5, activation=tf.nn.sigmoid)\n",
    "with tf.name_scope('loss'):\n",
    "  loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))\n",
    "with tf.name_scope('train'):\n",
    "  train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:  # tensorflow version < 0.12\n",
    "    writer = tf.train.SummaryWriter('logs/', sess.graph)\n",
    "else: # tensorflow version >= 0.12\n",
    "    writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nLy-UqwUX0B"
   },
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: xtrain, ys: ytrain})\n",
    "    if i % 50 == 0:\n",
    "        # to see the step improvement\n",
    "        print(sess.run(loss, feed_dict={xs: xtrain, ys: ytrain}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mRBeuT1FDXz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ELRBXpTFH8J"
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "P6bQ-WZFFmcP",
    "outputId": "2d65f8c4-74d0-425e-db05-8c35b8ce1b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZlCaOsI9F9Up"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c9RTpFvXGIaV",
    "outputId": "70929386-b89a-445f-f36a-72fbfcd181f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  result2=sess.run(input1,feed_dict={input1:[7.]})\n",
    "  print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHjWX-fvRBg4"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZlxF3imufXb"
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Ifr2KQ2lREEy",
    "outputId": "de800f1f-6e56-4efc-e686-fbda6b862181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1156\n",
      "0.6279\n",
      "0.7325\n",
      "0.7706\n",
      "0.8001\n",
      "0.8138\n",
      "0.8277\n",
      "0.8361\n",
      "0.8416\n",
      "0.8492\n",
      "0.8513\n",
      "0.8554\n",
      "0.856\n",
      "0.862\n",
      "0.8628\n",
      "0.8631\n",
      "0.8694\n",
      "0.8715\n",
      "0.876\n",
      "0.8738\n",
      "0.8756\n",
      "0.8785\n",
      "0.8798\n",
      "0.8803\n",
      "0.8789\n",
      "0.8821\n",
      "0.8841\n",
      "0.8811\n",
      "0.8847\n",
      "0.8878\n",
      "0.8852\n",
      "0.8894\n",
      "0.8868\n",
      "0.8903\n",
      "0.8842\n",
      "0.8878\n",
      "0.8924\n",
      "0.8934\n",
      "0.8928\n",
      "0.8919\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result\n",
    "xs = tf.placeholder(tf.float32, [None, 784])\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "prediction = layer(xs, 784, 10, activation=tf.nn.softmax)\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "reduction_indices=[1])) \n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(2000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "  if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "stockprocessing.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
