{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:21.967100Z",
     "start_time": "2019-05-16T11:30:20.548986Z"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "\n",
    "from IPython.display import display\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import matplotlib as mpl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import ast\n",
    "import jieba\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import FastText\n",
    "from glove import Glove, Corpus\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# %matplotlib\n",
    "\n",
    "stopwords = [line.strip() for line in codecs.open(\n",
    "    r'./stopwords.txt', 'r', 'utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:22.821503Z",
     "start_time": "2019-05-16T11:30:21.970820Z"
    }
   },
   "outputs": [],
   "source": [
    "text = pd.read_csv(r'../../Data/TRAINSET_NEWS.csv')\n",
    "stock = pd.read_csv(r'../../Data/TRAINSET_STOCK.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:22.875069Z",
     "start_time": "2019-05-16T11:30:22.824532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>name</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>pe</th>\n",
       "      <th>pb</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140401</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1668.75</td>\n",
       "      <td>1668.54</td>\n",
       "      <td>1689.12</td>\n",
       "      <td>1689.07</td>\n",
       "      <td>22.13</td>\n",
       "      <td>1.33</td>\n",
       "      <td>34914.0</td>\n",
       "      <td>291113.0</td>\n",
       "      <td>41.51</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140402</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1688.72</td>\n",
       "      <td>1684.53</td>\n",
       "      <td>1693.41</td>\n",
       "      <td>1692.24</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>36300.0</td>\n",
       "      <td>289020.0</td>\n",
       "      <td>41.63</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140403</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1693.05</td>\n",
       "      <td>1679.85</td>\n",
       "      <td>1697.73</td>\n",
       "      <td>1685.71</td>\n",
       "      <td>-6.53</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>31403.0</td>\n",
       "      <td>259464.0</td>\n",
       "      <td>41.38</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140404</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1681.92</td>\n",
       "      <td>1680.34</td>\n",
       "      <td>1698.44</td>\n",
       "      <td>1698.25</td>\n",
       "      <td>12.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>28648.0</td>\n",
       "      <td>240940.0</td>\n",
       "      <td>41.76</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140408</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1693.24</td>\n",
       "      <td>1692.22</td>\n",
       "      <td>1706.84</td>\n",
       "      <td>1706.84</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.51</td>\n",
       "      <td>35012.0</td>\n",
       "      <td>312423.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_code  trade_date  name     open      low     high    close  change  \\\n",
       "0   801010    20140401  农林牧渔  1668.75  1668.54  1689.12  1689.07   22.13   \n",
       "1   801010    20140402  农林牧渔  1688.72  1684.53  1693.41  1692.24    3.17   \n",
       "2   801010    20140403  农林牧渔  1693.05  1679.85  1697.73  1685.71   -6.53   \n",
       "3   801010    20140404  农林牧渔  1681.92  1680.34  1698.44  1698.25   12.54   \n",
       "4   801010    20140408  农林牧渔  1693.24  1692.22  1706.84  1706.84    8.59   \n",
       "\n",
       "   pct_change      vol    amount     pe    pb  y  \n",
       "0        1.33  34914.0  291113.0  41.51  2.77  1  \n",
       "1        0.19  36300.0  289020.0  41.63  2.79  1  \n",
       "2       -0.39  31403.0  259464.0  41.38  2.78  0  \n",
       "3        0.74  28648.0  240940.0  41.76  2.80  1  \n",
       "4        0.51  35012.0  312423.0  42.00  2.79  1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:22.965686Z",
     "start_time": "2019-05-16T11:30:22.879849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>801010</th>\n",
       "      <th>801020</th>\n",
       "      <th>801030</th>\n",
       "      <th>801040</th>\n",
       "      <th>801050</th>\n",
       "      <th>801080</th>\n",
       "      <th>801110</th>\n",
       "      <th>801120</th>\n",
       "      <th>801130</th>\n",
       "      <th>...</th>\n",
       "      <th>801730</th>\n",
       "      <th>801740</th>\n",
       "      <th>801750</th>\n",
       "      <th>801760</th>\n",
       "      <th>801770</th>\n",
       "      <th>801780</th>\n",
       "      <th>801790</th>\n",
       "      <th>801880</th>\n",
       "      <th>801890</th>\n",
       "      <th>802600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ts_code trade_date  801010  801020  801030  801040  801050  801080  801110  \\\n",
       "0       2014-04-01       1       1       1       1       1       1       1   \n",
       "1       2014-04-02       1       1       0       1       1       0       0   \n",
       "2       2014-04-03       0       0       1       0       1       1       1   \n",
       "3       2014-04-04       1       1       1       1       1       1       1   \n",
       "4       2014-04-08       1       1       1       1       1       1       1   \n",
       "\n",
       "ts_code  801120  801130  ...  801730  801740  801750  801760  801770  801780  \\\n",
       "0             1       1  ...       1       1       1       1       1       0   \n",
       "1             1       0  ...       0       0       0       0       0       1   \n",
       "2             0       0  ...       1       0       1       1       1       0   \n",
       "3             1       1  ...       1       1       1       1       1       1   \n",
       "4             1       1  ...       1       1       1       1       1       1   \n",
       "\n",
       "ts_code  801790  801880  801890  802600  \n",
       "0             1       1       1       1  \n",
       "1             1       1       0       0  \n",
       "2             1       0       0       1  \n",
       "3             1       1       1       1  \n",
       "4             1       1       1       1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df = (stock.loc[(stock['y'] == 1)]).groupby(['trade_date', 'ts_code'])[\n",
    "    'y'].count().unstack().fillna(0).astype(int).reset_index()\n",
    "target_df['trade_date'] = pd.to_datetime(\n",
    "    target_df['trade_date'], format='%Y%m%d', errors='ignore')\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:24.039474Z",
     "start_time": "2019-05-16T11:30:22.968286Z"
    }
   },
   "outputs": [],
   "source": [
    "w2vmodel = word2vec.Word2Vec.load(\"./Word_Embedding_Model/w2v.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:24.610724Z",
     "start_time": "2019-05-16T11:30:24.041654Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_model = Corpus.load('./Word_Embedding_Model/glov_corpus.model')\n",
    "glove = Glove.load('./Word_Embedding_Model/glove.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:26.417039Z",
     "start_time": "2019-05-16T11:30:24.614769Z"
    }
   },
   "outputs": [],
   "source": [
    "fttmodel = FastText.load(r'./Word_Embedding_Model/fasttext.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:26.427305Z",
     "start_time": "2019-05-16T11:30:26.419969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((126565, 100), 126565, 126565)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.word_vectors.shape, len(fttmodel.wv.vocab), len(w2vmodel.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:32.329525Z",
     "start_time": "2019-05-16T11:30:26.435505Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126565/126565 [00:02<00:00, 50339.61it/s]\n",
      "100%|██████████| 126565/126565 [00:00<00:00, 281995.69it/s]\n",
      "100%|██████████| 126565/126565 [00:02<00:00, 48256.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126566, 300) 0.9999960494919646 0.9999920989839294 0.9999920989839294\n"
     ]
    }
   ],
   "source": [
    "# word_list = list(w2vmodel.wv.vocab.keys())\n",
    "vector_size = 100\n",
    "word_index = glove.dictionary\n",
    "nb_words = len(word_index)\n",
    "\n",
    "count = 0.5\n",
    "embedding_word2vec_matrix = np.zeros((nb_words + 1, vector_size))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = w2vmodel[word] if word in w2vmodel else None\n",
    "    if embedding_vector is not None:\n",
    "        count += 1\n",
    "        embedding_word2vec_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        unk_vec = np.random.random(victor_size) * 0.5\n",
    "        unk_vec = unk_vec - unk_vec.mean()\n",
    "        embedding_word2vec_matrix[i] = unk_vec\n",
    "\n",
    "\n",
    "glove_count = 0\n",
    "embedding_glove_matrix = np.zeros((nb_words + 1, vector_size))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_glove_vector = glove.word_vectors[glove.dictionary[word]\n",
    "                                                ] if word in glove.dictionary else None\n",
    "    if embedding_glove_vector is not None:\n",
    "        glove_count += 1\n",
    "        embedding_glove_matrix[i] = embedding_glove_vector\n",
    "    else:\n",
    "        unk_vec = np.random.random(victor_size) * 0.5\n",
    "        unk_vec = unk_vec - unk_vec.mean()\n",
    "        embedding_glove_matrix[i] = unk_vec\n",
    "\n",
    "\n",
    "ftt_count = 0\n",
    "embedding_ftt_matrix = np.zeros((nb_words + 1, vector_size))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_ftt_vector = fttmodel[word] if word in fttmodel else None\n",
    "    if embedding_ftt_vector is not None:\n",
    "        ftt_count += 1\n",
    "        embedding_ftt_matrix[i] = embedding_ftt_vector\n",
    "    else:\n",
    "        unk_vec = np.random.random(victor_size) * 0.5\n",
    "        unk_vec = unk_vec - unk_vec.mean()\n",
    "        embedding_ftt_matrix[i] = unk_vec\n",
    "\n",
    "embedding_matrix = np.concatenate(\n",
    "    (embedding_word2vec_matrix, embedding_glove_matrix, embedding_ftt_matrix), axis=1)\n",
    "print(embedding_matrix.shape, count * 1.0 /\n",
    "      embedding_matrix.shape[0], glove_count*1.0/embedding_matrix.shape[0], ftt_count*1.0/embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:33.002973Z",
     "start_time": "2019-05-16T11:30:32.334090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>['习近平', '空军', '机关', '调研', '时', '强调', '加快', '建设...</td>\n",
       "      <td>['中共中央', '总书记', '国家', '主席', '中央军委', '主席', '习近平...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>['利比亚', '临时政府', '总理', '辞职']</td>\n",
       "      <td>['本月', '8', '号', '刚刚', '正式', '任命', '利比亚', '临时政...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>['关注', '乌克兰', '局势']</td>\n",
       "      <td>['代行', '乌克兰', '总统', '职责', '乌克兰', '议长', '图尔', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>['国内', '联播', '快讯']</td>\n",
       "      <td>['低碳', '中国', '行', '正式', '启动', '国家', '发展', '改革'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>['刘汉', '36', '人涉', '黑案', '继续', '开庭审理']</td>\n",
       "      <td>['刘汉', '刘维', '36', '人', '涉嫌', '犯', '组织', '领导',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                              title  \\\n",
       "0 2014-04-14  ['习近平', '空军', '机关', '调研', '时', '强调', '加快', '建设...   \n",
       "1 2014-04-14                        ['利比亚', '临时政府', '总理', '辞职']   \n",
       "2 2014-04-14                                ['关注', '乌克兰', '局势']   \n",
       "3 2014-04-14                                 ['国内', '联播', '快讯']   \n",
       "4 2014-04-14             ['刘汉', '36', '人涉', '黑案', '继续', '开庭审理']   \n",
       "\n",
       "                                             content  \n",
       "0  ['中共中央', '总书记', '国家', '主席', '中央军委', '主席', '习近平...  \n",
       "1  ['本月', '8', '号', '刚刚', '正式', '任命', '利比亚', '临时政...  \n",
       "2  ['代行', '乌克兰', '总统', '职责', '乌克兰', '议长', '图尔', '...  \n",
       "3  ['低碳', '中国', '行', '正式', '启动', '国家', '发展', '改革'...  \n",
       "4  ['刘汉', '刘维', '36', '人', '涉嫌', '犯', '组织', '领导',...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_text = pd.read_csv(r'./Word_Embedding_Model/seg_words.csv')\n",
    "seg_text['date'] = pd.to_datetime(\n",
    "    seg_text['date'], format='%Y%m%d', errors='ignore')\n",
    "seg_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:33.009463Z",
     "start_time": "2019-05-16T11:30:33.005642Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_func(x):\n",
    "    x = ast.literal_eval(x)\n",
    "    r_list = []\n",
    "    for i in x:\n",
    "        r_list += i\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge news title from the same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:30:34.143267Z",
     "start_time": "2019-05-16T11:30:33.011572Z"
    }
   },
   "outputs": [],
   "source": [
    "join_title = seg_text[['date', 'title']]\n",
    "join_title = join_title.groupby(\n",
    "    ['date'])['title'].apply(','.join).reset_index()\n",
    "join_title['title'] = join_title['title'].apply(merge_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge news content from the same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:04.631429Z",
     "start_time": "2019-05-16T11:30:34.145829Z"
    }
   },
   "outputs": [],
   "source": [
    "join_content = seg_text[['date', 'content']]\n",
    "join_content = join_content.groupby(\n",
    "    ['date'])['content'].apply(','.join).reset_index()\n",
    "join_content['content'] = join_content['content'].apply(merge_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact title and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:04.673961Z",
     "start_time": "2019-05-16T11:31:04.634768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>[习近平, 空军, 机关, 调研, 时, 强调, 加快, 建设, 一支, 空天, 一体, 攻...</td>\n",
       "      <td>[中共中央, 总书记, 国家, 主席, 中央军委, 主席, 习近平, 14, 日, 专程到,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>[医生, 贾永青, 传递, 爱, 感动, 国际, 联播, 快讯, 搜寻, MH370, 航班...</td>\n",
       "      <td>[几天, 我台, 走, 基层, 节目, 连续, 报道, 河北, 定州, 人民, 医院, 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>[国际, 联播, 快讯, 关注, 乌克兰, 局势, 乌, 军队, 东部, 地区, 开展, 强...</td>\n",
       "      <td>[约旦, 驻, 利比亚, 大使, 遭绑架, 利比亚, 外交部, 15, 号, 证实, 约旦,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>[凡人, 善举, 广西, 市民, 见义勇为, 巧施, 妙计, 擒, 劫匪, 国际, 联播, ...</td>\n",
       "      <td>[前两天, 广西北海, 一位, 市民, 目睹, 一起, 抢夺案, 后, 没有, 选择, 离开...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>[国际, 联播, 快讯, 俄罗斯, 总统, 俄, 民众, 直接对话, 普京, 乌, 境内, ...</td>\n",
       "      <td>[伊朗, 举行, 建军节, 阅兵式, 18, 号, 伊朗, 首都, 德黑兰, 南郊, 霍梅尼...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                              title  \\\n",
       "0 2014-04-14  [习近平, 空军, 机关, 调研, 时, 强调, 加快, 建设, 一支, 空天, 一体, 攻...   \n",
       "1 2014-04-15  [医生, 贾永青, 传递, 爱, 感动, 国际, 联播, 快讯, 搜寻, MH370, 航班...   \n",
       "2 2014-04-16  [国际, 联播, 快讯, 关注, 乌克兰, 局势, 乌, 军队, 东部, 地区, 开展, 强...   \n",
       "3 2014-04-17  [凡人, 善举, 广西, 市民, 见义勇为, 巧施, 妙计, 擒, 劫匪, 国际, 联播, ...   \n",
       "4 2014-04-18  [国际, 联播, 快讯, 俄罗斯, 总统, 俄, 民众, 直接对话, 普京, 乌, 境内, ...   \n",
       "\n",
       "                                             content  \n",
       "0  [中共中央, 总书记, 国家, 主席, 中央军委, 主席, 习近平, 14, 日, 专程到,...  \n",
       "1  [几天, 我台, 走, 基层, 节目, 连续, 报道, 河北, 定州, 人民, 医院, 32...  \n",
       "2  [约旦, 驻, 利比亚, 大使, 遭绑架, 利比亚, 外交部, 15, 号, 证实, 约旦,...  \n",
       "3  [前两天, 广西北海, 一位, 市民, 目睹, 一起, 抢夺案, 后, 没有, 选择, 离开...  \n",
       "4  [伊朗, 举行, 建军节, 阅兵式, 18, 号, 伊朗, 首都, 德黑兰, 南郊, 霍梅尼...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_text = join_title.merge(join_content, on='date')\n",
    "joined_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:04.757622Z",
     "start_time": "2019-05-16T11:31:04.676493Z"
    }
   },
   "outputs": [],
   "source": [
    "title_size = int(np.percentile(joined_text['title'].str.len(), 95))\n",
    "content_size = int(np.percentile(joined_text['content'].str.len(), 95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:06.409790Z",
     "start_time": "2019-05-16T11:31:04.760445Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News 2 Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:06.427995Z",
     "start_time": "2019-05-16T11:31:06.423788Z"
    }
   },
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.word_index = word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:16.554606Z",
     "start_time": "2019-05-16T11:31:06.439233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1814, 160), (1814, 3305))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_sequences = token.texts_to_sequences(join_title['title'].values)\n",
    "title_vec = pad_sequences(title_sequences, maxlen=title_size,\n",
    "                          padding='post', truncating='post', value=nb_words)\n",
    "\n",
    "content_sequences = token.texts_to_sequences(join_content['content'].values)\n",
    "content_vec = pad_sequences(content_sequences, maxlen=content_size,\n",
    "                            padding='post', truncating='post', value=nb_words)\n",
    "title_vec.shape, content_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:16.565532Z",
     "start_time": "2019-05-16T11:31:16.558250Z"
    }
   },
   "outputs": [],
   "source": [
    "train_roll_window = 10\n",
    "target_roll_window = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:16.660249Z",
     "start_time": "2019-05-16T11:31:16.572342Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_target = target_df.iloc[::-1]\n",
    "limit_target_index = (tmp_target['trade_date'] >= '2014-04-25')\n",
    "tmp_target = tmp_target[limit_target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:16.727610Z",
     "start_time": "2019-05-16T11:31:16.666154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049, 35)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:19.625876Z",
     "start_time": "2019-05-16T11:31:16.733514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1045/1045 [00:02<00:00, 369.63it/s]\n"
     ]
    }
   ],
   "source": [
    "rolling_date = []\n",
    "target_matrix = np.zeros(\n",
    "    (tmp_target.shape[0]-target_roll_window+1, 34*target_roll_window))\n",
    "for i in tqdm(range(0, tmp_target.shape[0]-4)):\n",
    "    tmp_i = tmp_target.iloc[i:i+5]\n",
    "    rolling_date.append(list(tmp_i['trade_date']))\n",
    "    target_matrix[i] = (tmp_i.drop(\n",
    "        columns=['trade_date'], axis=1).values).reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:19.639915Z",
     "start_time": "2019-05-16T11:31:19.630907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 170)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:19.748807Z",
     "start_time": "2019-05-16T11:31:19.644352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1045, 8000), (1045, 165250))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_title_matrix = np.zeros(\n",
    "    (target_matrix.shape[0], title_size*train_roll_window*target_roll_window))\n",
    "train_content_matrix = np.zeros(\n",
    "    (target_matrix.shape[0], content_size*train_roll_window*target_roll_window))\n",
    "train_title_matrix.shape, train_content_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.141870Z",
     "start_time": "2019-05-16T11:31:19.754492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1045/1045 [00:13<00:00, 78.50it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(rolling_date))):\n",
    "    tmp_title_row = np.zeros(\n",
    "        (target_roll_window, title_size*train_roll_window))\n",
    "    tmp_content_row = np.zeros(\n",
    "        (target_roll_window, content_size*train_roll_window))\n",
    "\n",
    "    for j in range(0, len(rolling_date[i])):\n",
    "        index_range = (join_title['date'] >= (\n",
    "            rolling_date[i][j] - pd.DateOffset(train_roll_window))) & (join_title['date'] < rolling_date[i][j])\n",
    "        tmp_title_row[j] = title_vec[index_range].reshape(1, -1)[0]\n",
    "        tmp_content_row[j] = content_vec[index_range].reshape(\n",
    "            1, -1)[0]\n",
    "    train_title_matrix[i] = tmp_title_row.reshape(1, -1)[0]\n",
    "    train_content_matrix[i] = tmp_content_row.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.154479Z",
     "start_time": "2019-05-16T11:31:33.146972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1045, 8000), (1045, 165250))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_title_matrix.shape, train_content_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nerual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.256136Z",
     "start_time": "2019-05-16T11:31:33.156999Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.335724Z",
     "start_time": "2019-05-16T11:31:33.258497Z"
    }
   },
   "outputs": [],
   "source": [
    "class nn:\n",
    "    def __init__(self, data, labels, wordvocab, embeddingDim, padSize, rollingWin, prerollingWin, preEmbedding):\n",
    "        self.dataset = data\n",
    "        self.labels = labels\n",
    "        self.wordvocab = wordvocab\n",
    "        self.embeddingDim = embeddingDim\n",
    "        self.padSize = padSize\n",
    "        self.prerollingWin = prerollingWin\n",
    "        self.rollingWin = rollingWin\n",
    "        self.preEmbedding = preEmbedding\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        vocabSize = len(self.wordvocab)\n",
    "        embeddingDim = self.embeddingDim  # the vector size a word need to be converted\n",
    "        maxlen = self.padSize*self.rollingWin * \\\n",
    "            self.prerollingWin  # the size of a sentence vector\n",
    "        outputDims = 34*self.prerollingWin\n",
    "        hiddenDims = 500\n",
    "\n",
    "        train_X = self.dataset\n",
    "        train_Y = self.labels\n",
    "\n",
    "        print(train_X.shape)\n",
    "        print(train_Y.shape)\n",
    "        max_features = vocabSize + 1\n",
    "        word_input = Input(shape=(maxlen,), dtype='float32', name='word_input')\n",
    "        mask = Masking(mask_value=0.)(word_input)\n",
    "        word_emb = Embedding(max_features, embeddingDim, weights=[self.preEmbedding],\n",
    "                             input_length=maxlen, name='word_emb')(mask)\n",
    "        bilstm1 = Bidirectional(\n",
    "            LSTM(hiddenDims, return_sequences=True))(word_emb)\n",
    "        bilstm2 = Bidirectional(\n",
    "            LSTM(hiddenDims, return_sequences=True))(bilstm1)\n",
    "        bilstm_d = Dropout(0.5)(bilstm2)\n",
    "        output = Dense(outputDims, activation='softmax')(bilstm_d)\n",
    "        model = Model(inputs=[word_input], outputs=output)\n",
    "        #sgd = optimizers.SGD(lr=0.1, decay=1e-3)\n",
    "        model.summary()\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'], )\n",
    "        self.model = model\n",
    "\n",
    "    def train(self):\n",
    "        batchSize = 32\n",
    "        result = self.model.fit(self.dataset, self.labels,\n",
    "                                batch_size=batchSize, epochs=10)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.835745Z",
     "start_time": "2019-05-16T11:31:33.338208Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_roll_window' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c25c5a2cf99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m lstm = nn(train_title_matrix, target_matrix, word_index, embeddingDim=300,\n\u001b[0;32m----> 2\u001b[0;31m           padSize=title_size, rollingWin=train_roll_window, prerollingWin=pre_roll_window, preEmbedding=embedding_matrix)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pre_roll_window' is not defined"
     ]
    }
   ],
   "source": [
    "lstm = nn(train_title_matrix, target_matrix, word_index, embeddingDim=300,\n",
    "          padSize=title_size, rollingWin=train_roll_window, prerollingWin=pre_roll_window, preEmbedding=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.852375Z",
     "start_time": "2019-05-16T11:30:20.694Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.854988Z",
     "start_time": "2019-05-16T11:30:20.705Z"
    }
   },
   "outputs": [],
   "source": [
    "def bi_gru_model(sent_length, embeddings_weight, output_num):\n",
    "    print(\"get_text_gru3\")\n",
    "    content = Input(shape=(sent_length,), dtype='int32')\n",
    "    embedding = Embedding(\n",
    "        name=\"word_embedding\",\n",
    "        input_dim=embeddings_weight.shape[0],\n",
    "        weights=[embeddings_weight],\n",
    "        output_dim=embeddings_weight.shape[1],\n",
    "        trainable=False)\n",
    "\n",
    "    x = SpatialDropout1D(0.2)(embedding(content))\n",
    "\n",
    "#     x = Bidirectional(CuDNNGRU(200, return_sequences=True))(x)\n",
    "#     x = Bidirectional(CuDNNGRU(200, return_sequences=True))(x)\n",
    "\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)\n",
    "    x = Bidirectional(GRU(200, return_sequences=True))(x)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "\n",
    "    x = Dropout(0.2)(Activation(activation=\"relu\")(\n",
    "        BatchNormalization()(Dense(1000)(conc))))\n",
    "    x = Activation(activation=\"relu\")(BatchNormalization()(Dense(500)(x)))\n",
    "    output = Dense(output_num, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=content, outputs=output)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.858067Z",
     "start_time": "2019-05-16T11:30:20.718Z"
    }
   },
   "outputs": [],
   "source": [
    "gru_model = bi_gru_model(sent_length=(title_size*train_roll_window*target_roll_window),\n",
    "                         embeddings_weight=embedding_matrix, output_num=34*target_roll_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:31:33.860626Z",
     "start_time": "2019-05-16T11:30:20.738Z"
    }
   },
   "outputs": [],
   "source": [
    "gru_model.fit(train_title_matrix, target_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "377px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
