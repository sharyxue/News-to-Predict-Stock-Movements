{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:15:52.767392Z",
     "start_time": "2019-05-16T04:15:52.754816Z"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "\n",
    "from IPython.display import display\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import matplotlib as mpl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import ast\n",
    "import jieba\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import FastText\n",
    "from glove import Glove, Corpus\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# %matplotlib\n",
    "\n",
    "stopwords = [line.strip() for line in codecs.open(\n",
    "    r'./stopwords.txt', 'r', 'utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:15:53.703278Z",
     "start_time": "2019-05-16T04:15:52.772061Z"
    }
   },
   "outputs": [],
   "source": [
    "text = pd.read_csv(r'../../Data/TRAINSET_NEWS.csv')\n",
    "stock = pd.read_csv(r'../../Data/TRAINSET_STOCK.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:15:53.751188Z",
     "start_time": "2019-05-16T04:15:53.705818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>name</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>pe</th>\n",
       "      <th>pb</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140401</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1668.75</td>\n",
       "      <td>1668.54</td>\n",
       "      <td>1689.12</td>\n",
       "      <td>1689.07</td>\n",
       "      <td>22.13</td>\n",
       "      <td>1.33</td>\n",
       "      <td>34914.0</td>\n",
       "      <td>291113.0</td>\n",
       "      <td>41.51</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140402</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1688.72</td>\n",
       "      <td>1684.53</td>\n",
       "      <td>1693.41</td>\n",
       "      <td>1692.24</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>36300.0</td>\n",
       "      <td>289020.0</td>\n",
       "      <td>41.63</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140403</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1693.05</td>\n",
       "      <td>1679.85</td>\n",
       "      <td>1697.73</td>\n",
       "      <td>1685.71</td>\n",
       "      <td>-6.53</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>31403.0</td>\n",
       "      <td>259464.0</td>\n",
       "      <td>41.38</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140404</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1681.92</td>\n",
       "      <td>1680.34</td>\n",
       "      <td>1698.44</td>\n",
       "      <td>1698.25</td>\n",
       "      <td>12.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>28648.0</td>\n",
       "      <td>240940.0</td>\n",
       "      <td>41.76</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801010</td>\n",
       "      <td>20140408</td>\n",
       "      <td>农林牧渔</td>\n",
       "      <td>1693.24</td>\n",
       "      <td>1692.22</td>\n",
       "      <td>1706.84</td>\n",
       "      <td>1706.84</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.51</td>\n",
       "      <td>35012.0</td>\n",
       "      <td>312423.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_code  trade_date  name     open      low     high    close  change  \\\n",
       "0   801010    20140401  农林牧渔  1668.75  1668.54  1689.12  1689.07   22.13   \n",
       "1   801010    20140402  农林牧渔  1688.72  1684.53  1693.41  1692.24    3.17   \n",
       "2   801010    20140403  农林牧渔  1693.05  1679.85  1697.73  1685.71   -6.53   \n",
       "3   801010    20140404  农林牧渔  1681.92  1680.34  1698.44  1698.25   12.54   \n",
       "4   801010    20140408  农林牧渔  1693.24  1692.22  1706.84  1706.84    8.59   \n",
       "\n",
       "   pct_change      vol    amount     pe    pb  y  \n",
       "0        1.33  34914.0  291113.0  41.51  2.77  1  \n",
       "1        0.19  36300.0  289020.0  41.63  2.79  1  \n",
       "2       -0.39  31403.0  259464.0  41.38  2.78  0  \n",
       "3        0.74  28648.0  240940.0  41.76  2.80  1  \n",
       "4        0.51  35012.0  312423.0  42.00  2.79  1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:37:12.106675Z",
     "start_time": "2019-05-16T04:37:12.081245Z"
    }
   },
   "outputs": [],
   "source": [
    "target_df = (stock.loc[(stock['y'] == 1)]).groupby(['trade_date', 'ts_code'])[\n",
    "    'y'].count().unstack().fillna(0).astype(int).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:39:50.078850Z",
     "start_time": "2019-05-16T04:39:50.070167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1064, 35)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_min_date = target_df['trade_date'].min()\n",
    "target_max_date = target_df['trade_date'].max()\n",
    "target_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:15:55.938880Z",
     "start_time": "2019-05-16T04:15:53.887977Z"
    }
   },
   "outputs": [],
   "source": [
    "w2vmodel = word2vec.Word2Vec.load(\"./Word_Embedding_Model/w2v.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:00.258768Z",
     "start_time": "2019-05-16T04:15:55.941079Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_model = Corpus.load('./Word_Embedding_Model/glov_corpus.model')\n",
    "glove = Glove.load('./Word_Embedding_Model/glove.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:20.614667Z",
     "start_time": "2019-05-16T04:16:00.262327Z"
    }
   },
   "outputs": [],
   "source": [
    "fttmodel = FastText.load(r'./Word_Embedding_Model/fasttext.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:20.625599Z",
     "start_time": "2019-05-16T04:16:20.617356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((126565, 100), 126565, 126565)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.word_vectors.shape, len(fttmodel.wv.vocab), len(w2vmodel.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:26.612377Z",
     "start_time": "2019-05-16T04:16:20.629259Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126565/126565 [00:02<00:00, 50726.37it/s]\n",
      "100%|██████████| 126565/126565 [00:00<00:00, 276137.13it/s]\n",
      "100%|██████████| 126565/126565 [00:02<00:00, 46209.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126566, 300) 0.9999960494919646 0.9999920989839294 0.9999920989839294\n"
     ]
    }
   ],
   "source": [
    "# word_list = list(w2vmodel.wv.vocab.keys())\n",
    "vector_size = 100\n",
    "word_index = glove.dictionary\n",
    "nb_words = len(word_index)\n",
    "\n",
    "count = 0.5\n",
    "embedding_word2vec_matrix = np.zeros((nb_words + 1, vector_size))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = w2vmodel[word] if word in w2vmodel else None\n",
    "    if embedding_vector is not None:\n",
    "        count += 1\n",
    "        embedding_word2vec_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        unk_vec = np.random.random(victor_size) * 0.5\n",
    "        unk_vec = unk_vec - unk_vec.mean()\n",
    "        embedding_word2vec_matrix[i] = unk_vec\n",
    "\n",
    "\n",
    "glove_count = 0\n",
    "embedding_glove_matrix = np.zeros((nb_words + 1, vector_size))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_glove_vector = glove.word_vectors[glove.dictionary[word]\n",
    "                                                ] if word in glove.dictionary else None\n",
    "    if embedding_glove_vector is not None:\n",
    "        glove_count += 1\n",
    "        embedding_glove_matrix[i] = embedding_glove_vector\n",
    "    else:\n",
    "        unk_vec = np.random.random(victor_size) * 0.5\n",
    "        unk_vec = unk_vec - unk_vec.mean()\n",
    "        embedding_glove_matrix[i] = unk_vec\n",
    "\n",
    "\n",
    "ftt_count = 0\n",
    "embedding_ftt_matrix = np.zeros((nb_words + 1, vector_size))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_ftt_vector = fttmodel[word] if word in fttmodel else None\n",
    "    if embedding_ftt_vector is not None:\n",
    "        ftt_count += 1\n",
    "        embedding_ftt_matrix[i] = embedding_ftt_vector\n",
    "    else:\n",
    "        unk_vec = np.random.random(victor_size) * 0.5\n",
    "        unk_vec = unk_vec - unk_vec.mean()\n",
    "        embedding_ftt_matrix[i] = unk_vec\n",
    "\n",
    "embedding_matrix = np.concatenate(\n",
    "    (embedding_word2vec_matrix, embedding_glove_matrix, embedding_ftt_matrix), axis=1)\n",
    "print(embedding_matrix.shape, count * 1.0 /\n",
    "      embedding_matrix.shape[0], glove_count*1.0/embedding_matrix.shape[0], ftt_count*1.0/embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:27.692107Z",
     "start_time": "2019-05-16T04:16:26.615491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20140414</td>\n",
       "      <td>['习近平', '空军', '机关', '调研', '时', '强调', '加快', '建设...</td>\n",
       "      <td>['中共中央', '总书记', '国家', '主席', '中央军委', '主席', '习近平...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20140414</td>\n",
       "      <td>['利比亚', '临时政府', '总理', '辞职']</td>\n",
       "      <td>['本月', '8', '号', '刚刚', '正式', '任命', '利比亚', '临时政...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20140414</td>\n",
       "      <td>['关注', '乌克兰', '局势']</td>\n",
       "      <td>['代行', '乌克兰', '总统', '职责', '乌克兰', '议长', '图尔', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20140414</td>\n",
       "      <td>['国内', '联播', '快讯']</td>\n",
       "      <td>['低碳', '中国', '行', '正式', '启动', '国家', '发展', '改革'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20140414</td>\n",
       "      <td>['刘汉', '36', '人涉', '黑案', '继续', '开庭审理']</td>\n",
       "      <td>['刘汉', '刘维', '36', '人', '涉嫌', '犯', '组织', '领导',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                              title  \\\n",
       "0  20140414  ['习近平', '空军', '机关', '调研', '时', '强调', '加快', '建设...   \n",
       "1  20140414                        ['利比亚', '临时政府', '总理', '辞职']   \n",
       "2  20140414                                ['关注', '乌克兰', '局势']   \n",
       "3  20140414                                 ['国内', '联播', '快讯']   \n",
       "4  20140414             ['刘汉', '36', '人涉', '黑案', '继续', '开庭审理']   \n",
       "\n",
       "                                             content  \n",
       "0  ['中共中央', '总书记', '国家', '主席', '中央军委', '主席', '习近平...  \n",
       "1  ['本月', '8', '号', '刚刚', '正式', '任命', '利比亚', '临时政...  \n",
       "2  ['代行', '乌克兰', '总统', '职责', '乌克兰', '议长', '图尔', '...  \n",
       "3  ['低碳', '中国', '行', '正式', '启动', '国家', '发展', '改革'...  \n",
       "4  ['刘汉', '刘维', '36', '人', '涉嫌', '犯', '组织', '领导',...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_text = pd.read_csv(r'./Word_Embedding_Model/seg_words.csv')\n",
    "seg_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:27.703800Z",
     "start_time": "2019-05-16T04:16:27.698067Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_func(x):\n",
    "    x = ast.literal_eval(x)\n",
    "    r_list = []\n",
    "    for i in x:\n",
    "        r_list += i\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge news title from the same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:28.831282Z",
     "start_time": "2019-05-16T04:16:27.707805Z"
    }
   },
   "outputs": [],
   "source": [
    "join_title = seg_text[['date', 'title']]\n",
    "join_title = join_title.groupby(\n",
    "    ['date'])['title'].apply(','.join).reset_index()\n",
    "join_title['title'] = join_title['title'].apply(merge_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge news content from the same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:45.414633Z",
     "start_time": "2019-05-16T04:16:28.834586Z"
    }
   },
   "outputs": [],
   "source": [
    "join_content = seg_text[['date', 'content']]\n",
    "join_content = join_content.groupby(\n",
    "    ['date'])['content'].apply(','.join).reset_index()\n",
    "join_content['content'] = join_content['content'].apply(merge_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact title and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:45.465674Z",
     "start_time": "2019-05-16T04:16:45.418167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20140414</td>\n",
       "      <td>[习近平, 空军, 机关, 调研, 时, 强调, 加快, 建设, 一支, 空天, 一体, 攻...</td>\n",
       "      <td>[中共中央, 总书记, 国家, 主席, 中央军委, 主席, 习近平, 14, 日, 专程到,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20140415</td>\n",
       "      <td>[医生, 贾永青, 传递, 爱, 感动, 国际, 联播, 快讯, 搜寻, MH370, 航班...</td>\n",
       "      <td>[几天, 我台, 走, 基层, 节目, 连续, 报道, 河北, 定州, 人民, 医院, 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20140416</td>\n",
       "      <td>[国际, 联播, 快讯, 关注, 乌克兰, 局势, 乌, 军队, 东部, 地区, 开展, 强...</td>\n",
       "      <td>[约旦, 驻, 利比亚, 大使, 遭绑架, 利比亚, 外交部, 15, 号, 证实, 约旦,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20140417</td>\n",
       "      <td>[凡人, 善举, 广西, 市民, 见义勇为, 巧施, 妙计, 擒, 劫匪, 国际, 联播, ...</td>\n",
       "      <td>[前两天, 广西北海, 一位, 市民, 目睹, 一起, 抢夺案, 后, 没有, 选择, 离开...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20140418</td>\n",
       "      <td>[国际, 联播, 快讯, 俄罗斯, 总统, 俄, 民众, 直接对话, 普京, 乌, 境内, ...</td>\n",
       "      <td>[伊朗, 举行, 建军节, 阅兵式, 18, 号, 伊朗, 首都, 德黑兰, 南郊, 霍梅尼...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                              title  \\\n",
       "0  20140414  [习近平, 空军, 机关, 调研, 时, 强调, 加快, 建设, 一支, 空天, 一体, 攻...   \n",
       "1  20140415  [医生, 贾永青, 传递, 爱, 感动, 国际, 联播, 快讯, 搜寻, MH370, 航班...   \n",
       "2  20140416  [国际, 联播, 快讯, 关注, 乌克兰, 局势, 乌, 军队, 东部, 地区, 开展, 强...   \n",
       "3  20140417  [凡人, 善举, 广西, 市民, 见义勇为, 巧施, 妙计, 擒, 劫匪, 国际, 联播, ...   \n",
       "4  20140418  [国际, 联播, 快讯, 俄罗斯, 总统, 俄, 民众, 直接对话, 普京, 乌, 境内, ...   \n",
       "\n",
       "                                             content  \n",
       "0  [中共中央, 总书记, 国家, 主席, 中央军委, 主席, 习近平, 14, 日, 专程到,...  \n",
       "1  [几天, 我台, 走, 基层, 节目, 连续, 报道, 河北, 定州, 人民, 医院, 32...  \n",
       "2  [约旦, 驻, 利比亚, 大使, 遭绑架, 利比亚, 外交部, 15, 号, 证实, 约旦,...  \n",
       "3  [前两天, 广西北海, 一位, 市民, 目睹, 一起, 抢夺案, 后, 没有, 选择, 离开...  \n",
       "4  [伊朗, 举行, 建军节, 阅兵式, 18, 号, 伊朗, 首都, 德黑兰, 南郊, 霍梅尼...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_text = join_title.merge(join_content, on='date')\n",
    "joined_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:39:13.403861Z",
     "start_time": "2019-05-16T04:39:13.394421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20140414, 20190401)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_min_date = joined_text['date'].min()\n",
    "text_max_date = joined_text['date'].max()\n",
    "text_min_date, text_max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:41:15.779323Z",
     "start_time": "2019-05-16T04:41:15.770854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_text['date'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:45.489849Z",
     "start_time": "2019-05-16T04:16:45.467933Z"
    }
   },
   "outputs": [],
   "source": [
    "title_size = int(np.percentile(joined_text['title'].str.len(), 95))\n",
    "content_size = int(np.percentile(joined_text['content'].str.len(), 95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:47.181011Z",
     "start_time": "2019-05-16T04:16:45.494179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News 2 Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:16:47.188995Z",
     "start_time": "2019-05-16T04:16:47.184446Z"
    }
   },
   "outputs": [],
   "source": [
    "# def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "#     num_embeddings, embedding_dim = weights_matrix.size()\n",
    "#     emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "#     emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "#     if non_trainable:\n",
    "#         emb_layer.weight.requires_grad = False\n",
    "\n",
    "#     return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "\n",
    "# class GRU(nn.Module):\n",
    "#     def __init__(self, weights_matrix, hidden_size, num_layers):\n",
    "#         super(self).__init__()\n",
    "#         self.embedding, num_embeddings, embedding_dim = create_emb_layer(\n",
    "#             weights_matrix, True)\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.gru = nn.GRU(embedding_dim, hidden_size,\n",
    "#                           num_layers, batch_first=True)\n",
    "\n",
    "#     def forward(self, inp, hidden):\n",
    "#         return self.gru(self.embedding(inp), hidden)\n",
    "\n",
    "#     def init_hidden(self, batch_size):\n",
    "#         return Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:24:18.759327Z",
     "start_time": "2019-05-16T04:24:18.755209Z"
    }
   },
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.word_index = word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T04:28:25.484994Z",
     "start_time": "2019-05-16T04:28:20.544619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1814, 160), (1814, 3305))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_sequences = token.texts_to_sequences(join_title['title'].values)\n",
    "title_vec = pad_sequences(title_sequences, maxlen=title_size,\n",
    "                          padding='post', truncating='post', value=0)\n",
    "\n",
    "content_sequences = token.texts_to_sequences(join_content['content'].values)\n",
    "content_vec = pad_sequences(content_sequences, maxlen=content_size,\n",
    "                            padding='post', truncating='post', value=0)\n",
    "title_vec.shape, content_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "377px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
